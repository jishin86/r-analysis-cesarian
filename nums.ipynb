{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "library(\"foreign\")\n",
    "rawdata=read.arff(\"./caesarian.csv.arff\")\n",
    "colnames(rawdata) = c(\"Age\",\"DN\",\"DT\",\"BP\",\"HP\",\"CS\")\n",
    "str(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"No rows containging missing value\"\n"
     ]
    }
   ],
   "source": [
    "## check missing value\n",
    "norg=length(rawdata[,1])\n",
    "## remove rows containing missing values  \n",
    "rawdata=na.omit(rawdata)\n",
    "morg=length(rawdata[,1])\n",
    "if( norg == morg ){ print(\"No rows containging missing value\")}\n",
    "if( norg != morg ){ print(\"Number of missing value=\"); print(norg-morg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrplot 0.84 loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n",
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : num  1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : num  1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : num  3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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",
      "text/plain": [
       "Plot with title “”"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check collinearity btw features\n",
    "library(corrplot)\n",
    "str(rawdata)\n",
    "rawdata.num=rawdata\n",
    "for ( i in 1:5)  { rawdata.num[,i] = as.numeric(rawdata[,i]) }\n",
    "str(rawdata.num)\n",
    "\n",
    "rawdata.cor = cor(rawdata.num[,1:5])\n",
    "corrplot.mixed(rawdata.cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : num  1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : num  1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : num  3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n",
      "'data.frame':\t24 obs. of  6 variables:\n",
      " $ Age: num  10 12 6 16 19 9 8 10 11 2 ...\n",
      " $ DN : num  2 1 2 3 1 1 1 1 1 1 ...\n",
      " $ DT : num  1 1 1 1 1 3 3 2 1 1 ...\n",
      " $ BP : num  2 3 2 2 2 1 1 2 1 2 ...\n",
      " $ HP : num  1 1 1 1 1 1 2 1 2 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 2 1 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "##sample from category data\n",
    "\n",
    "## dividing orginal data by ratio for tran, test\n",
    "\n",
    "#fix random seed\n",
    "set.seed(123)\n",
    "\n",
    "# make index vector(row number) for two type(x=2 : train, test) of samples \n",
    "# with probability weight : train:test = 7:3  \n",
    "# in number of sample=nrow(rawdata3)=80 )\n",
    "# replace : If TRUE, same data from orginal can be repeat in new sample\n",
    "ind = sample(2, nrow(rawdata), replace=TRUE, prob=c(0.7,0.3))\n",
    "\n",
    "## log reg from numeric data\n",
    "traindata.num = rawdata.num[ind==1,] \n",
    "str(traindata.num) ## 80datas * 70% = 56datas\n",
    "testdata.num = rawdata.num[ind==2,] \n",
    "str(testdata.num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = CS ~ ., family = binomial, data = traindata.num)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9359  -1.0293   0.5149   0.8963   1.5201  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept) -2.78921    1.76248  -1.583  0.11353   \n",
       "Age          0.05993    0.07465   0.803  0.42208   \n",
       "DN          -0.13158    0.44714  -0.294  0.76856   \n",
       "DT          -0.14475    0.38001  -0.381  0.70327   \n",
       "BP           0.24278    0.45556   0.533  0.59409   \n",
       "HP           1.79571    0.67783   2.649  0.00807 **\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 65.160  on 50  degrees of freedom\n",
       "AIC: 77.16\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data (numeric type)\n",
    "full.fit_num = glm(CS~., family=binomial, data=traindata.num)\n",
    "summary(full.fit_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for profiling to be done...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-6.52697337</td><td>0.4877489  </td></tr>\n",
       "\t<tr><th scope=row>Age</th><td>-0.08732483</td><td>0.2112889  </td></tr>\n",
       "\t<tr><th scope=row>DN</th><td>-1.03231225</td><td>0.7578197  </td></tr>\n",
       "\t<tr><th scope=row>DT</th><td>-0.90278716</td><td>0.6074640  </td></tr>\n",
       "\t<tr><th scope=row>BP</th><td>-0.65111496</td><td>1.1662917  </td></tr>\n",
       "\t<tr><th scope=row>HP</th><td> 0.53867485</td><td>3.2457265  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -6.52697337 & 0.4877489  \\\\\n",
       "\tAge & -0.08732483 & 0.2112889  \\\\\n",
       "\tDN & -1.03231225 & 0.7578197  \\\\\n",
       "\tDT & -0.90278716 & 0.6074640  \\\\\n",
       "\tBP & -0.65111496 & 1.1662917  \\\\\n",
       "\tHP &  0.53867485 & 3.2457265  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|---|---|---|---|---|\n",
       "| (Intercept) | -6.52697337 | 0.4877489   | \n",
       "| Age | -0.08732483 | 0.2112889   | \n",
       "| DN | -1.03231225 | 0.7578197   | \n",
       "| DT | -0.90278716 | 0.6074640   | \n",
       "| BP | -0.65111496 | 1.1662917   | \n",
       "| HP |  0.53867485 | 3.2457265   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %       97.5 %   \n",
       "(Intercept) -6.52697337 0.4877489\n",
       "Age         -0.08732483 0.2112889\n",
       "DN          -1.03231225 0.7578197\n",
       "DT          -0.90278716 0.6074640\n",
       "BP          -0.65111496 1.1662917\n",
       "HP           0.53867485 3.2457265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.0614699983020103</dd>\n",
       "\t<dt>Age</dt>\n",
       "\t\t<dd>1.06176467162423</dd>\n",
       "\t<dt>DN</dt>\n",
       "\t\t<dd>0.876713446845346</dd>\n",
       "\t<dt>DT</dt>\n",
       "\t\t<dd>0.865241464773045</dd>\n",
       "\t<dt>BP</dt>\n",
       "\t\t<dd>1.27478659375149</dd>\n",
       "\t<dt>HP</dt>\n",
       "\t\t<dd>6.02374908760084</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.0614699983020103\n",
       "\\item[Age] 1.06176467162423\n",
       "\\item[DN] 0.876713446845346\n",
       "\\item[DT] 0.865241464773045\n",
       "\\item[BP] 1.27478659375149\n",
       "\\item[HP] 6.02374908760084\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.0614699983020103Age\n",
       ":   1.06176467162423DN\n",
       ":   0.876713446845346DT\n",
       ":   0.865241464773045BP\n",
       ":   1.27478659375149HP\n",
       ":   6.02374908760084\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)         Age          DN          DT          BP          HP \n",
       "  0.0614700   1.0617647   0.8767134   0.8652415   1.2747866   6.0237491 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confidence interval for train\n",
    "confint(full.fit_num)\n",
    "#odd's ratio\n",
    "exp(coef(full.fit_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Age</dt>\n",
       "\t\t<dd>1.33015063824177</dd>\n",
       "\t<dt>DN</dt>\n",
       "\t\t<dd>1.34968142169978</dd>\n",
       "\t<dt>DT</dt>\n",
       "\t\t<dd>1.04643917128553</dd>\n",
       "\t<dt>BP</dt>\n",
       "\t\t<dd>1.08009357286157</dd>\n",
       "\t<dt>HP</dt>\n",
       "\t\t<dd>1.05576325650969</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Age] 1.33015063824177\n",
       "\\item[DN] 1.34968142169978\n",
       "\\item[DT] 1.04643917128553\n",
       "\\item[BP] 1.08009357286157\n",
       "\\item[HP] 1.05576325650969\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Age\n",
       ":   1.33015063824177DN\n",
       ":   1.34968142169978DT\n",
       ":   1.04643917128553BP\n",
       ":   1.08009357286157HP\n",
       ":   1.05576325650969\n",
       "\n"
      ],
      "text/plain": [
       "     Age       DN       DT       BP       HP \n",
       "1.330151 1.349681 1.046439 1.080094 1.055763 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variance inflation factor for train\n",
    "library(car)\n",
    "vif(full.fit_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 17 12\n",
       "  1  6 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse) \n",
    "traindata.num$prob = predict(full.fit_num, type=\"response\")\n",
    "traindata.num$predict = rep(0, length(traindata.num$prob)) # make empty vector as 0 (False)\n",
    "traindata.num$predict[traindata.num$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(traindata.num$predict, traindata.num$CS)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 17 12\n",
       "         1  6 21\n",
       "                                          \n",
       "               Accuracy : 0.6786          \n",
       "                 95% CI : (0.5404, 0.7971)\n",
       "    No Information Rate : 0.5893          \n",
       "    P-Value [Acc > NIR] : 0.1098          \n",
       "                                          \n",
       "                  Kappa : 0.3612          \n",
       " Mcnemar's Test P-Value : 0.2386          \n",
       "                                          \n",
       "            Sensitivity : 0.6364          \n",
       "            Specificity : 0.7391          \n",
       "         Pos Pred Value : 0.7778          \n",
       "         Neg Pred Value : 0.5862          \n",
       "             Prevalence : 0.5893          \n",
       "         Detection Rate : 0.3750          \n",
       "   Detection Prevalence : 0.4821          \n",
       "      Balanced Accuracy : 0.6877          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 17 6 12 21\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.679 0.361 0.54 0.797 0.589 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.636 0.739 0.778 0.586 0.778 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.6363636 \n",
      "Pos Pred Value \n",
      "     0.7777778 \n",
      " Accuracy \n",
      "0.6785714 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(traindata.num$predict), as.factor(traindata.num$CS), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "    0 1\n",
       "  0 6 7\n",
       "  1 5 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test sample\n",
    "testdata.num$prob = predict(full.fit_num, newdata=testdata.num, type=\"response\")\n",
    "testdata.num$predict = rep(0, length(testdata.num$prob))\n",
    "testdata.num$predict[testdata.num$prob>0.5] = 1\n",
    "table(testdata.num$predict, testdata.num$CS)\n",
    "mean(testdata.num$predict == testdata.num$CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 6 7\n",
       "         1 5 6\n",
       "                                          \n",
       "               Accuracy : 0.5             \n",
       "                 95% CI : (0.2912, 0.7088)\n",
       "    No Information Rate : 0.5417          \n",
       "    P-Value [Acc > NIR] : 0.7313          \n",
       "                                          \n",
       "                  Kappa : 0.0069          \n",
       " Mcnemar's Test P-Value : 0.7728          \n",
       "                                          \n",
       "            Sensitivity : 0.4615          \n",
       "            Specificity : 0.5455          \n",
       "         Pos Pred Value : 0.5455          \n",
       "         Neg Pred Value : 0.4615          \n",
       "             Prevalence : 0.5417          \n",
       "         Detection Rate : 0.2500          \n",
       "   Detection Prevalence : 0.4583          \n",
       "      Balanced Accuracy : 0.5035          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 6 5 7 6\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.5 0.0069 0.2912 0.7088 0.5417 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.462 0.545 0.545 0.462 0.545 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.4615385 \n",
      "Pos Pred Value \n",
      "     0.5454545 \n",
      "Accuracy \n",
      "     0.5 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for test sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(testdata.num$predict), as.factor(testdata.num$CS), positive=\"1\")\n",
    "# Sensitivity = Precision\n",
    "# Pos Pred Value = Recall\n",
    "# Accuracy\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: leaps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Age'</li>\n",
       "\t<li>'DN'</li>\n",
       "\t<li>'DT'</li>\n",
       "\t<li>'BP'</li>\n",
       "\t<li>'HP'</li>\n",
       "\t<li>'y'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Age'\n",
       "\\item 'DN'\n",
       "\\item 'DT'\n",
       "\\item 'BP'\n",
       "\\item 'HP'\n",
       "\\item 'y'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Age'\n",
       "2. 'DN'\n",
       "3. 'DT'\n",
       "4. 'BP'\n",
       "5. 'HP'\n",
       "6. 'y'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Age\" \"DN\"  \"DT\"  \"BP\"  \"HP\"  \"y\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Age</th><th scope=col>DN</th><th scope=col>DT</th><th scope=col>BP</th><th scope=col>HP</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 6</td><td>1 </td><td>1 </td><td>3 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10</td><td>2 </td><td>2 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10</td><td>1 </td><td>2 </td><td>1 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>11</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>12</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>11</td><td>1 </td><td>2 </td><td>2 </td><td>1 </td><td>1 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & Age & DN & DT & BP & HP & y\\\\\n",
       "\\hline\n",
       "\t1 &  6 & 1  & 1  & 3  & 1  & 0 \\\\\n",
       "\t3 & 10 & 2  & 2  & 2  & 1  & 0 \\\\\n",
       "\t6 & 10 & 1  & 2  & 1  & 1  & 0 \\\\\n",
       "\t7 & 11 & 2  & 1  & 2  & 1  & 0 \\\\\n",
       "\t9 & 12 & 2  & 1  & 2  & 1  & 0 \\\\\n",
       "\t10 & 11 & 1  & 2  & 2  & 1  & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Age | DN | DT | BP | HP | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 1 |  6 | 1  | 1  | 3  | 1  | 0  | \n",
       "| 3 | 10 | 2  | 2  | 2  | 1  | 0  | \n",
       "| 6 | 10 | 1  | 2  | 1  | 1  | 0  | \n",
       "| 7 | 11 | 2  | 1  | 2  | 1  | 0  | \n",
       "| 9 | 12 | 2  | 1  | 2  | 1  | 0  | \n",
       "| 10 | 11 | 1  | 2  | 2  | 1  | 1  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Age DN DT BP HP y\n",
       "1   6  1  1  3  1  0\n",
       "3  10  2  2  2  1  0\n",
       "6  10  1  2  1  1  0\n",
       "7  11  2  1  2  1  0\n",
       "9  12  2  1  2  1  0\n",
       "10 11  1  2  2  1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : num  1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : num  1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : num  3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ y  : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "#best subset reg.\n",
    "library(bestglm)\n",
    "cvdata = traindata.num[,-7:-8]\n",
    "orgcolname=colnames(rawdata)\n",
    "orgcolname[6]=\"y\"\n",
    "orgcolname\n",
    "colnames(cvdata)=orgcolname\n",
    "head(cvdata)\n",
    "#cvdata$y= as.numeric(traindata$CS)\n",
    "str(cvdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan-Tatar search since family is non-gaussian.\n",
      "Warning message in mean.default(y[!iTest]):\n",
      "“argument is not numeric or logical: returning NA”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in mean.default(y[!iTest]):\n",
      "“argument is not numeric or logical: returning NA”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in mean.default(y[!iTest]):\n",
      "“argument is not numeric or logical: returning NA”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in Ops.factor(y[iTest], yHat):\n",
      "“‘-’ not meaningful for factors”Warning message in min(which(cverrs < cutOff)):\n",
      "“no non-missing arguments to min; returning Inf”Warning message in bestglm(Xy = cvdata, IC = \"CV\", CVArgs = list(Method = \"HTF\", :\n",
      "“NAs introduced by coercion to integer range”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in `[.data.frame`(Xy, , c(bestset[-1], FALSE), drop = FALSE): undefined columns selected\n",
     "output_type": "error",
     "traceback": [
      "Error in `[.data.frame`(Xy, , c(bestset[-1], FALSE), drop = FALSE): undefined columns selected\nTraceback:\n",
      "1. bestglm(Xy = cvdata, IC = \"CV\", CVArgs = list(Method = \"HTF\", \n .     K = 3, REP = 1), family = binomial)",
      "2. glm(y ~ ., family = family, data = data.frame(Xy[, c(bestset[-1], \n .     FALSE), drop = FALSE], y = y), ...)",
      "3. eval(mf, parent.frame())",
      "4. eval(mf, parent.frame())",
      "5. stats::model.frame(formula = y ~ ., data = data.frame(Xy[, c(bestset[-1], \n .     FALSE), drop = FALSE], y = y), drop.unused.levels = TRUE)",
      "6. model.frame.default(formula = y ~ ., data = data.frame(Xy[, c(bestset[-1], \n .     FALSE), drop = FALSE], y = y), drop.unused.levels = TRUE)",
      "7. is.data.frame(data)",
      "8. data.frame(Xy[, c(bestset[-1], FALSE), drop = FALSE], y = y)",
      "9. Xy[, c(bestset[-1], FALSE), drop = FALSE]",
      "10. `[.data.frame`(Xy, , c(bestset[-1], FALSE), drop = FALSE)",
      "11. stop(\"undefined columns selected\")"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"CV\", CVArgs=list(Method=\"HTF\", K=3, REP=1), family=binomial)\n",
    "summary(cvdata.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan-Tatar search since family is non-gaussian.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BIC\n",
       "BICq equivalent for q in (0.0581156714516717, 0.852591422895177)\n",
       "Best Model:\n",
       "             Estimate Std. Error   z value    Pr(>|z|)\n",
       "(Intercept) -2.168908  0.8937965 -2.426624 0.015240046\n",
       "HP           1.863526  0.6532164  2.852847 0.004332954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#BIC\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"BIC\", family=binomial)\n",
    "cvdata.bestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = CS ~ HP, family = binomial, data = traindata.num)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.8704  -1.0508   0.6181   0.7910   1.3095  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept)  -2.1689     0.8938  -2.427  0.01524 * \n",
       "HP            1.8635     0.6532   2.853  0.00433 **\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 66.241  on 54  degrees of freedom\n",
       "AIC: 70.241\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. again using best feature\n",
    "\n",
    "full.fit_best = glm(CS~HP, family=binomial, data=traindata.num)\n",
    "summary(full.fit_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for profiling to be done...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-4.0017413</td><td>-0.4644816</td></tr>\n",
       "\t<tr><th scope=row>HP</th><td> 0.6565598</td><td> 3.2646848</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -4.0017413 & -0.4644816\\\\\n",
       "\tHP &  0.6565598 &  3.2646848\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|---|\n",
       "| (Intercept) | -4.0017413 | -0.4644816 | \n",
       "| HP |  0.6565598 |  3.2646848 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %      97.5 %    \n",
       "(Intercept) -4.0017413 -0.4644816\n",
       "HP           0.6565598  3.2646848"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.114302376439714</dd>\n",
       "\t<dt>HP</dt>\n",
       "\t\t<dd>6.44642857142857</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.114302376439714\n",
       "\\item[HP] 6.44642857142857\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.114302376439714HP\n",
       ":   6.44642857142857\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)          HP \n",
       "  0.1143024   6.4464286 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confidence interval\n",
    "confint(full.fit_best)\n",
    "#odd's ratio\n",
    "exp(coef(full.fit_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in vif.default(full.fit_best): model contains fewer than 2 terms\n",
     "output_type": "error",
     "traceback": [
      "Error in vif.default(full.fit_best): model contains fewer than 2 terms\nTraceback:\n",
      "1. vif(full.fit_best)",
      "2. vif.default(full.fit_best)",
      "3. stop(\"model contains fewer than 2 terms\")"
     ]
    }
   ],
   "source": [
    "# variance inflation factor\n",
    "library(car)\n",
    "vif(full.fit_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 19 14\n",
       "  1  4 19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "traindata.num$prob = predict(full.fit_best, type=\"response\")\n",
    "traindata.num$predict = rep(0, length(traindata.num$prob)) # make empty vector as 0 (False)\n",
    "traindata.num$predict[traindata.num$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(traindata.num$predict, traindata.num$CS)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 19 14\n",
       "         1  4 19\n",
       "                                          \n",
       "               Accuracy : 0.6786          \n",
       "                 95% CI : (0.5404, 0.7971)\n",
       "    No Information Rate : 0.5893          \n",
       "    P-Value [Acc > NIR] : 0.10983         \n",
       "                                          \n",
       "                  Kappa : 0.377           \n",
       " Mcnemar's Test P-Value : 0.03389         \n",
       "                                          \n",
       "            Sensitivity : 0.5758          \n",
       "            Specificity : 0.8261          \n",
       "         Pos Pred Value : 0.8261          \n",
       "         Neg Pred Value : 0.5758          \n",
       "             Prevalence : 0.5893          \n",
       "         Detection Rate : 0.3393          \n",
       "   Detection Prevalence : 0.4107          \n",
       "      Balanced Accuracy : 0.7009          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 19 4 14 19\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.679 0.377 0.54 0.797 0.589 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.576 0.826 0.826 0.576 0.826 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.5757576 \n",
      "Pos Pred Value \n",
      "      0.826087 \n",
      " Accuracy \n",
      "0.6785714 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(traindata.num$predict), as.factor(traindata.num$CS), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "    0 1\n",
       "  0 9 8\n",
       "  1 2 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.583333333333333"
      ],
      "text/latex": [
       "0.583333333333333"
      ],
      "text/markdown": [
       "0.583333333333333"
      ],
      "text/plain": [
       "[1] 0.5833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test sample\n",
    "testdata.num$prob = predict(full.fit_best, newdata=testdata.num, type=\"response\")\n",
    "testdata.num$predict = rep(0, length(testdata.num$prob))\n",
    "testdata.num$predict[testdata.num$prob>0.5] = 1\n",
    "table(testdata.num$predict, testdata.num$CS)\n",
    "mean(testdata.num$predict == testdata.num$CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 9 8\n",
       "         1 2 5\n",
       "                                          \n",
       "               Accuracy : 0.5833          \n",
       "                 95% CI : (0.3664, 0.7789)\n",
       "    No Information Rate : 0.5417          \n",
       "    P-Value [Acc > NIR] : 0.4213          \n",
       "                                          \n",
       "                  Kappa : 0.1946          \n",
       " Mcnemar's Test P-Value : 0.1138          \n",
       "                                          \n",
       "            Sensitivity : 0.3846          \n",
       "            Specificity : 0.8182          \n",
       "         Pos Pred Value : 0.7143          \n",
       "         Neg Pred Value : 0.5294          \n",
       "             Prevalence : 0.5417          \n",
       "         Detection Rate : 0.2083          \n",
       "   Detection Prevalence : 0.2917          \n",
       "      Balanced Accuracy : 0.6014          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 9 2 8 5\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.583 0.195 0.366 0.779 0.542 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.385 0.818 0.714 0.529 0.714 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.3846154 \n",
      "Pos Pred Value \n",
      "     0.7142857 \n",
      " Accuracy \n",
      "0.5833333 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for test sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(testdata.num$predict), as.factor(testdata.num$CS), positive=\"1\")\n",
    "# Sensitivity = Precision\n",
    "# Pos Pred Value = Recall\n",
    "# Accuracy\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Age</th><th scope=col>DN</th><th scope=col>DT</th><th scope=col>BP</th><th scope=col>HP</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 6</td><td>1 </td><td>1 </td><td>3 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10</td><td>2 </td><td>2 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10</td><td>1 </td><td>2 </td><td>1 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>11</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>12</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>11</td><td>1 </td><td>2 </td><td>2 </td><td>1 </td><td>1 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & Age & DN & DT & BP & HP & y\\\\\n",
       "\\hline\n",
       "\t1 &  6 & 1  & 1  & 3  & 1  & 0 \\\\\n",
       "\t3 & 10 & 2  & 2  & 2  & 1  & 0 \\\\\n",
       "\t6 & 10 & 1  & 2  & 1  & 1  & 0 \\\\\n",
       "\t7 & 11 & 2  & 1  & 2  & 1  & 0 \\\\\n",
       "\t9 & 12 & 2  & 1  & 2  & 1  & 0 \\\\\n",
       "\t10 & 11 & 1  & 2  & 2  & 1  & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Age | DN | DT | BP | HP | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 1 |  6 | 1  | 1  | 3  | 1  | 0  | \n",
       "| 3 | 10 | 2  | 2  | 2  | 1  | 0  | \n",
       "| 6 | 10 | 1  | 2  | 1  | 1  | 0  | \n",
       "| 7 | 11 | 2  | 1  | 2  | 1  | 0  | \n",
       "| 9 | 12 | 2  | 1  | 2  | 1  | 0  | \n",
       "| 10 | 11 | 1  | 2  | 2  | 1  | 1  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Age DN DT BP HP y\n",
       "1   6  1  1  3  1  0\n",
       "3  10  2  2  2  1  0\n",
       "6  10  1  2  1  1  0\n",
       "7  11  2  1  2  1  0\n",
       "9  12  2  1  2  1  0\n",
       "10 11  1  2  2  1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"DN\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3  4 \n",
       "26 21  7  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "54  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"DT\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "28 15 13 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "28 28 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"BP\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "12 28 16 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3\n",
       "2. 2\n",
       "3. 1\n",
       "4. 2\n",
       "5. 2\n",
       "6. 2\n",
       "7. 1\n",
       "8. 2\n",
       "9. 2\n",
       "10. 1\n",
       "11. 2\n",
       "12. 3\n",
       "13. 2\n",
       "14. 1\n",
       "15. 3\n",
       "16. 3\n",
       "17. 3\n",
       "18. 2\n",
       "19. 3\n",
       "20. 2\n",
       "21. 3\n",
       "22. 2\n",
       "23. 3\n",
       "24. 2\n",
       "25. 2\n",
       "26. 1\n",
       "27. 3\n",
       "28. 2\n",
       "29. 3\n",
       "30. 2\n",
       "31. 3\n",
       "32. 2\n",
       "33. 2\n",
       "34. 3\n",
       "35. 2\n",
       "36. 2\n",
       "37. 1\n",
       "38. 1\n",
       "39. 2\n",
       "40. 2\n",
       "41. 1\n",
       "42. 3\n",
       "43. 3\n",
       "44. 2\n",
       "45. 1\n",
       "46. 2\n",
       "47. 2\n",
       "48. 1\n",
       "49. 1\n",
       "50. 2\n",
       "51. 3\n",
       "52. 2\n",
       "53. 2\n",
       "54. 3\n",
       "55. 1\n",
       "56. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 3 2 1 2 2 2 1 2 2 1 2 3 2 1 3 3 3 2 3 2 3 2 3 2 2 1 3 2 3 2 3 2 2 3 2 2 1 1\n",
       "[39] 2 2 1 3 3 2 1 2 2 1 1 2 3 2 2 3 1 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "28 28 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ DT : num  0 1 1 0 0 1 1 1 0 1 ...\n",
      " $ BP : num  0 1 0 1 1 1 0 1 1 0 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ y  : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n",
      "[1] \"HP\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2 \n",
       "33 23 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Binarization\n",
    "#from train data\n",
    "traindata.bin = traindata.num[,-7:-8]\n",
    "orgname=colnames(traindata.bin)\n",
    "orgname[6] = \"y\"\n",
    "colnames(traindata.bin) = orgname\n",
    "head(traindata.bin)\n",
    "\n",
    "\n",
    "## change columns with 3 level to 2 level \n",
    "#attribute 'Delivery number' { 1,2,3,4 } \n",
    "# -> DN==1( new 0) or others( new 1)\n",
    "print(\"DN\")\n",
    "table(traindata.bin$DN)\n",
    "DN = ifelse(traindata.bin$DN ==4  , 1, 0 ) \n",
    "#traindata.bin$DN = as.factor(DN)\n",
    "traindata.bin$DN = DN\n",
    "table(traindata.bin$DN)\n",
    "\n",
    "#attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}\n",
    "# -> DT==0(new 0) or others( new 1)\n",
    "print(\"DT\")\n",
    "table(traindata.bin$DT)\n",
    "DT = ifelse(traindata.bin$DT ==1  , 0, 1 ) \n",
    "#traindata.bin$DT = as.factor(DT)\n",
    "traindata.bin$DT=DT\n",
    "table(traindata.bin$DT)\n",
    "\n",
    "#attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }\n",
    "# -> DT=0,1 ( new 0) or others ( new 1)\n",
    "print(\"BP\")\n",
    "table(traindata.bin$BP)\n",
    "traindata.bin$BP\n",
    "BP = ifelse(traindata.bin$BP == 2  , 1, 0 ) \n",
    "#traindata.bin$BP = as.factor(BP)\n",
    "traindata.bin$BP = BP\n",
    "table(traindata.bin$BP)\n",
    "\n",
    "str(traindata.bin)\n",
    "\n",
    "\n",
    "#HP -> no change\n",
    "print(\"HP\")\n",
    "table(traindata.bin$HP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan-Tatar search since family is non-gaussian.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BIC\n",
       "BICq equivalent for q in (0.248994566768918, 0.64280917082642)\n",
       "Best Model:\n",
       "             Estimate Std. Error   z value   Pr(>|z|)\n",
       "(Intercept) -1.072201  1.0172182 -1.054052 0.29185917\n",
       "BP          -1.545456  0.6392007 -2.417794 0.01561492\n",
       "HP           1.673696  0.6881141  2.432294 0.01500352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#BIC\n",
    "traindata.bin.bestset=bestglm(Xy=traindata.bin, IC=\"BIC\", family=binomial)\n",
    "traindata.bin.bestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ BP + HP, family = binomial, data = traindata.bin)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.4988  -0.8107   0.4423   0.8990   1.5954  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)  -1.0722     1.0172  -1.054   0.2919  \n",
       "BP           -1.5455     0.6392  -2.418   0.0156 *\n",
       "HP            1.6737     0.6881   2.432   0.0150 *\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 60.008  on 53  degrees of freedom\n",
       "AIC: 66.008\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data (numeric type about age only)\n",
    "full.fit_num_bin = glm(y~BP+HP, family=binomial, data=traindata.bin)\n",
    "summary(full.fit_num_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 13  7\n",
       "  1 10 26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "traindata.bin$prob = predict(full.fit_num_bin, type=\"response\")\n",
    "traindata.bin$predict = rep(0, length(traindata.bin$prob)) # make empty vector as 0 (False)\n",
    "traindata.bin$predict[traindata.bin$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(traindata.bin$predict, traindata.bin$y)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 13  7\n",
       "         1 10 26\n",
       "                                         \n",
       "               Accuracy : 0.6964         \n",
       "                 95% CI : (0.559, 0.8122)\n",
       "    No Information Rate : 0.5893         \n",
       "    P-Value [Acc > NIR] : 0.06586        \n",
       "                                         \n",
       "                  Kappa : 0.3602         \n",
       " Mcnemar's Test P-Value : 0.62763        \n",
       "                                         \n",
       "            Sensitivity : 0.7879         \n",
       "            Specificity : 0.5652         \n",
       "         Pos Pred Value : 0.7222         \n",
       "         Neg Pred Value : 0.6500         \n",
       "             Prevalence : 0.5893         \n",
       "         Detection Rate : 0.4643         \n",
       "   Detection Prevalence : 0.6429         \n",
       "      Balanced Accuracy : 0.6765         \n",
       "                                         \n",
       "       'Positive' Class : 1              \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 13 10 7 26\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.696 0.36 0.559 0.812 0.589 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.788 0.565 0.722 0.65 0.722 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.7878788 \n",
      "Pos Pred Value \n",
      "     0.7222222 \n",
      " Accuracy \n",
      "0.6964286 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(traindata.bin$predict), as.factor(traindata.bin$y), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "    0 1\n",
       "  0 5 4\n",
       "  1 6 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "testdata.bin$prob = predict(full.fit_num_bin, newdata=testdata.bin, type=\"response\")\n",
    "testdata.bin$predict = rep(0, length(testdata.bin$prob)) # make empty vector as 0 (False)\n",
    "testdata.bin$predict[testdata.bin$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(testdata.bin$predict, testdata.bin$y)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 5 4\n",
       "         1 6 9\n",
       "                                          \n",
       "               Accuracy : 0.5833          \n",
       "                 95% CI : (0.3664, 0.7789)\n",
       "    No Information Rate : 0.5417          \n",
       "    P-Value [Acc > NIR] : 0.4213          \n",
       "                                          \n",
       "                  Kappa : 0.1489          \n",
       " Mcnemar's Test P-Value : 0.7518          \n",
       "                                          \n",
       "            Sensitivity : 0.6923          \n",
       "            Specificity : 0.4545          \n",
       "         Pos Pred Value : 0.6000          \n",
       "         Neg Pred Value : 0.5556          \n",
       "             Prevalence : 0.5417          \n",
       "         Detection Rate : 0.3750          \n",
       "   Detection Prevalence : 0.6250          \n",
       "      Balanced Accuracy : 0.5734          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 5 6 4 9\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.583 0.149 0.366 0.779 0.542 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.692 0.455 0.6 0.556 0.6 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.6923077 \n",
      "Pos Pred Value \n",
      "           0.6 \n",
      " Accuracy \n",
      "0.5833333 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(testdata.bin$predict), as.factor(testdata.bin$y), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ ., family = binomial, data = traindata.bin)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.7500  -0.8868   0.3002   0.7790   1.9638  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept)   -0.43120    1.39253  -0.310   0.7568   \n",
       "Age            0.01776    0.07178   0.247   0.8046   \n",
       "DN            16.97808 2147.45903   0.008   0.9937   \n",
       "DT            -1.03625    0.77515  -1.337   0.1813   \n",
       "BP            -2.09340    0.78030  -2.683   0.0073 **\n",
       "HP             1.61217    0.73013   2.208   0.0272 * \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 55.147  on 50  degrees of freedom\n",
       "AIC: 67.147\n",
       "\n",
       "Number of Fisher Scoring iterations: 16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data (numeric type about age only)\n",
    "full.fit_num_bin = glm(y~., family=binomial, data=traindata.bin)\n",
    "summary(full.fit_num_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 15  6\n",
       "  1  8 27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "traindata.bin$prob = predict(full.fit_num_bin, type=\"response\")\n",
    "traindata.bin$predict = rep(0, length(traindata.bin$prob)) # make empty vector as 0 (False)\n",
    "traindata.bin$predict[traindata.bin$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(traindata.bin$predict, traindata.bin$y)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 15  6\n",
       "         1  8 27\n",
       "                                          \n",
       "               Accuracy : 0.75            \n",
       "                 95% CI : (0.6163, 0.8561)\n",
       "    No Information Rate : 0.5893          \n",
       "    P-Value [Acc > NIR] : 0.009055        \n",
       "                                          \n",
       "                  Kappa : 0.4766          \n",
       " Mcnemar's Test P-Value : 0.789268        \n",
       "                                          \n",
       "            Sensitivity : 0.8182          \n",
       "            Specificity : 0.6522          \n",
       "         Pos Pred Value : 0.7714          \n",
       "         Neg Pred Value : 0.7143          \n",
       "             Prevalence : 0.5893          \n",
       "         Detection Rate : 0.4821          \n",
       "   Detection Prevalence : 0.6250          \n",
       "      Balanced Accuracy : 0.7352          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 15 8 6 27\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.75 0.477 0.616 0.856 0.589 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.818 0.652 0.771 0.714 0.771 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.8181818 \n",
      "Pos Pred Value \n",
      "     0.7714286 \n",
      "Accuracy \n",
      "    0.75 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(traindata.bin$predict), as.factor(traindata.bin$y), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Age</th><th scope=col>DN</th><th scope=col>DT</th><th scope=col>BP</th><th scope=col>HP</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>10</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>12</td><td>1 </td><td>1 </td><td>3 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 6</td><td>2 </td><td>1 </td><td>2 </td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>16</td><td>3 </td><td>1 </td><td>2 </td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><th scope=row>11</th><td>19</td><td>1 </td><td>1 </td><td>2 </td><td>1 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>16</th><td> 9</td><td>1 </td><td>3 </td><td>1 </td><td>1 </td><td>0 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & Age & DN & DT & BP & HP & y\\\\\n",
       "\\hline\n",
       "\t2 & 10 & 2  & 1  & 2  & 1  & 1 \\\\\n",
       "\t4 & 12 & 1  & 1  & 3  & 1  & 0 \\\\\n",
       "\t5 &  6 & 2  & 1  & 2  & 1  & 1 \\\\\n",
       "\t8 & 16 & 3  & 1  & 2  & 1  & 1 \\\\\n",
       "\t11 & 19 & 1  & 1  & 2  & 1  & 0 \\\\\n",
       "\t16 &  9 & 1  & 3  & 1  & 1  & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Age | DN | DT | BP | HP | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 2 | 10 | 2  | 1  | 2  | 1  | 1  | \n",
       "| 4 | 12 | 1  | 1  | 3  | 1  | 0  | \n",
       "| 5 |  6 | 2  | 1  | 2  | 1  | 1  | \n",
       "| 8 | 16 | 3  | 1  | 2  | 1  | 1  | \n",
       "| 11 | 19 | 1  | 1  | 2  | 1  | 0  | \n",
       "| 16 |  9 | 1  | 3  | 1  | 1  | 0  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Age DN DT BP HP y\n",
       "2  10  2  1  2  1  1\n",
       "4  12  1  1  3  1  0\n",
       "5   6  2  1  2  1  1\n",
       "8  16  3  1  2  1  1\n",
       "11 19  1  1  2  1  0\n",
       "16  9  1  3  1  1  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"DN\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "15  6  3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0 \n",
       "24 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"DT\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "18  2  4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "18  6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"BP\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       " 8 12  4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 3\n",
       "3. 2\n",
       "4. 2\n",
       "5. 2\n",
       "6. 1\n",
       "7. 1\n",
       "8. 2\n",
       "9. 1\n",
       "10. 2\n",
       "11. 1\n",
       "12. 2\n",
       "13. 2\n",
       "14. 2\n",
       "15. 1\n",
       "16. 3\n",
       "17. 1\n",
       "18. 3\n",
       "19. 3\n",
       "20. 2\n",
       "21. 2\n",
       "22. 1\n",
       "23. 1\n",
       "24. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 2 3 2 2 2 1 1 2 1 2 1 2 2 2 1 3 1 3 3 2 2 1 1 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "12 12 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t24 obs. of  6 variables:\n",
      " $ Age: num  10 12 6 16 19 9 8 10 11 2 ...\n",
      " $ DN : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ DT : num  0 0 0 0 0 1 1 1 0 0 ...\n",
      " $ BP : num  1 0 1 1 1 0 0 1 0 1 ...\n",
      " $ HP : num  1 1 1 1 1 1 2 1 2 1 ...\n",
      " $ y  : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 2 1 2 1 ...\n",
      "[1] \"HP\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2 \n",
       "17  7 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Binarization\n",
    "#from test data\n",
    "testdata.bin = testdata.num[,-7:-8]\n",
    "orgname=colnames(testdata.bin)\n",
    "orgname[6] = \"y\"\n",
    "colnames(testdata.bin) = orgname\n",
    "head(testdata.bin)\n",
    "\n",
    "\n",
    "## change columns with 3 level to 2 level \n",
    "#attribute 'Delivery number' { 1,2,3,4 } \n",
    "# -> DN==1( new 0) or others( new 1)\n",
    "print(\"DN\")\n",
    "table(testdata.bin$DN)\n",
    "DN = ifelse(testdata.bin$DN ==4  , 1, 0 ) \n",
    "#testdata.bin$DN = as.factor(DN)\n",
    "testdata.bin$DN = DN\n",
    "table(testdata.bin$DN)\n",
    "\n",
    "#attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}\n",
    "# -> DT==0(new 0) or others( new 1)\n",
    "print(\"DT\")\n",
    "table(testdata.bin$DT)\n",
    "DT = ifelse(testdata.bin$DT ==1  , 0, 1 ) \n",
    "#testdata.bin$DT = as.factor(DT)\n",
    "testdata.bin$DT = DT\n",
    "table(testdata.bin$DT)\n",
    "\n",
    "#attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }\n",
    "# -> DT=0,1 ( new 0) or others ( new 1)\n",
    "print(\"BP\")\n",
    "table(testdata.bin$BP)\n",
    "testdata.bin$BP\n",
    "BP = ifelse(testdata.bin$BP == 2  , 1, 0 ) \n",
    "#testdata.bin$BP = as.factor(BP)\n",
    "testdata.bin$BP = BP\n",
    "table(testdata.bin$BP)\n",
    "\n",
    "str(testdata.bin)\n",
    "\n",
    "\n",
    "#HP -> no change\n",
    "print(\"HP\")\n",
    "table(testdata.bin$HP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "    0 1\n",
       "  0 5 4\n",
       "  1 6 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "testdata.bin$prob = predict(full.fit_num_bin, newdata=testdata.bin, type=\"response\")\n",
    "testdata.bin$predict = rep(0, length(testdata.bin$prob)) # make empty vector as 0 (False)\n",
    "testdata.bin$predict[testdata.bin$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(testdata.bin$predict, testdata.bin$y)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 5 4\n",
       "         1 6 9\n",
       "                                          \n",
       "               Accuracy : 0.5833          \n",
       "                 95% CI : (0.3664, 0.7789)\n",
       "    No Information Rate : 0.5417          \n",
       "    P-Value [Acc > NIR] : 0.4213          \n",
       "                                          \n",
       "                  Kappa : 0.1489          \n",
       " Mcnemar's Test P-Value : 0.7518          \n",
       "                                          \n",
       "            Sensitivity : 0.6923          \n",
       "            Specificity : 0.4545          \n",
       "         Pos Pred Value : 0.6000          \n",
       "         Neg Pred Value : 0.5556          \n",
       "             Prevalence : 0.5417          \n",
       "         Detection Rate : 0.3750          \n",
       "   Detection Prevalence : 0.6250          \n",
       "      Balanced Accuracy : 0.5734          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 5 6 4 9\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.583 0.149 0.366 0.779 0.542 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.692 0.455 0.6 0.556 0.6 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.6923077 \n",
      "Pos Pred Value \n",
      "           0.6 \n",
      " Accuracy \n",
      "0.5833333 \n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for train sample\n",
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(testdata.bin$predict), as.factor(testdata.bin$y), positive=\"1\")\n",
    "confm\n",
    "str(confm)\n",
    "# Sensitivity = Precision\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "print(Precision)\n",
    "# Pos Pred Value = Recall\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "print(Recall)\n",
    "# Accuracy\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
