{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "library(\"foreign\")\n",
    "rawdata=read.arff(\"./caesarian.csv.arff\")\n",
    "colnames(rawdata) = c(\"Age\",\"DN\",\"DT\",\"BP\",\"HP\",\"CS\")\n",
    "str(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"No rows containging missing value\"\n"
     ]
    }
   ],
   "source": [
    "## check missing value\n",
    "norg=length(rawdata[,1])\n",
    "## remove rows containing missing values  \n",
    "rawdata=na.omit(rawdata)\n",
    "morg=length(rawdata[,1])\n",
    "if( norg == morg ){ print(\"No rows containging missing value\")}\n",
    "if( norg != morg ){ print(\"Number of missing value=\"); print(norg-morg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“attributes are not identical across measure variables; they will be dropped”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CS</th><th scope=col>variable</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0 </td><td>DN</td><td>1 </td></tr>\n",
       "\t<tr><td>1 </td><td>DN</td><td>2 </td></tr>\n",
       "\t<tr><td>0 </td><td>DN</td><td>2 </td></tr>\n",
       "\t<tr><td>0 </td><td>DN</td><td>1 </td></tr>\n",
       "\t<tr><td>1 </td><td>DN</td><td>2 </td></tr>\n",
       "\t<tr><td>0 </td><td>DN</td><td>1 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " CS & variable & value\\\\\n",
       "\\hline\n",
       "\t 0  & DN & 1 \\\\\n",
       "\t 1  & DN & 2 \\\\\n",
       "\t 0  & DN & 2 \\\\\n",
       "\t 0  & DN & 1 \\\\\n",
       "\t 1  & DN & 2 \\\\\n",
       "\t 0  & DN & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "CS | variable | value | \n",
       "|---|---|---|---|---|---|\n",
       "| 0  | DN | 1  | \n",
       "| 1  | DN | 2  | \n",
       "| 0  | DN | 2  | \n",
       "| 0  | DN | 1  | \n",
       "| 1  | DN | 2  | \n",
       "| 0  | DN | 1  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  CS variable value\n",
       "1 0  DN       1    \n",
       "2 1  DN       2    \n",
       "3 0  DN       2    \n",
       "4 0  DN       1    \n",
       "5 1  DN       2    \n",
       "6 0  DN       1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "DN DT BP HP \n",
       "80 80 80 80 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## change data from wide type to long type \n",
    "library(reshape2)\n",
    "rawdata.m = melt(rawdata[,-1], id.var=\"CS\")\n",
    "head(rawdata.m)\n",
    "table(rawdata.m$variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC9FBMVEUAAAABAQECAgIDAwME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\nkAABQl8kBLUAAAAISURBVAIE/h+kALyCHMWLOQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## boxplot\n",
    "library(ggplot2)\n",
    "ggplot(data=rawdata.m, aes(x=CS, y=value)) + geom_boxplot() + facet_wrap(~ variable, ncol=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Age</th><th scope=col>DN</th><th scope=col>DT</th><th scope=col>BP</th><th scope=col>HP</th><th scope=col>CS</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>22</td><td>1 </td><td>0 </td><td>2 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><td>26</td><td>2 </td><td>0 </td><td>1 </td><td>0 </td><td>1 </td></tr>\n",
       "\t<tr><td>26</td><td>2 </td><td>1 </td><td>1 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><td>28</td><td>1 </td><td>0 </td><td>2 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><td>22</td><td>2 </td><td>0 </td><td>1 </td><td>0 </td><td>1 </td></tr>\n",
       "\t<tr><td>26</td><td>1 </td><td>1 </td><td>0 </td><td>0 </td><td>0 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " Age & DN & DT & BP & HP & CS\\\\\n",
       "\\hline\n",
       "\t 22 & 1  & 0  & 2  & 0  & 0 \\\\\n",
       "\t 26 & 2  & 0  & 1  & 0  & 1 \\\\\n",
       "\t 26 & 2  & 1  & 1  & 0  & 0 \\\\\n",
       "\t 28 & 1  & 0  & 2  & 0  & 0 \\\\\n",
       "\t 22 & 2  & 0  & 1  & 0  & 1 \\\\\n",
       "\t 26 & 1  & 1  & 0  & 0  & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Age | DN | DT | BP | HP | CS | \n",
       "|---|---|---|---|---|---|\n",
       "| 22 | 1  | 0  | 2  | 0  | 0  | \n",
       "| 26 | 2  | 0  | 1  | 0  | 1  | \n",
       "| 26 | 2  | 1  | 1  | 0  | 0  | \n",
       "| 28 | 1  | 0  | 2  | 0  | 0  | \n",
       "| 22 | 2  | 0  | 1  | 0  | 1  | \n",
       "| 26 | 1  | 1  | 0  | 0  | 0  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Age DN DT BP HP CS\n",
       "1 22  1  0  2  0  0 \n",
       "2 26  2  0  1  0  1 \n",
       "3 26  2  1  1  0  0 \n",
       "4 28  1  0  2  0  0 \n",
       "5 22  2  0  1  0  1 \n",
       "6 26  1  1  0  0  0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      " rawdata$Age |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          17 |         0 |         1 |         1 | \n",
      "             |     0.425 |     0.314 |           | \n",
      "             |     0.000 |     1.000 |     0.013 | \n",
      "             |     0.000 |     0.022 |           | \n",
      "             |     0.000 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          18 |         1 |         1 |         2 | \n",
      "             |     0.026 |     0.020 |           | \n",
      "             |     0.500 |     0.500 |     0.025 | \n",
      "             |     0.029 |     0.022 |           | \n",
      "             |     0.013 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          19 |         0 |         2 |         2 | \n",
      "             |     0.850 |     0.628 |           | \n",
      "             |     0.000 |     1.000 |     0.025 | \n",
      "             |     0.000 |     0.043 |           | \n",
      "             |     0.000 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          20 |         1 |         2 |         3 | \n",
      "             |     0.059 |     0.044 |           | \n",
      "             |     0.333 |     0.667 |     0.037 | \n",
      "             |     0.029 |     0.043 |           | \n",
      "             |     0.013 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          21 |         0 |         2 |         2 | \n",
      "             |     0.850 |     0.628 |           | \n",
      "             |     0.000 |     1.000 |     0.025 | \n",
      "             |     0.000 |     0.043 |           | \n",
      "             |     0.000 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          22 |         2 |         2 |         4 | \n",
      "             |     0.053 |     0.039 |           | \n",
      "             |     0.500 |     0.500 |     0.050 | \n",
      "             |     0.059 |     0.043 |           | \n",
      "             |     0.025 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          23 |         1 |         0 |         1 | \n",
      "             |     0.778 |     0.575 |           | \n",
      "             |     1.000 |     0.000 |     0.013 | \n",
      "             |     0.029 |     0.000 |           | \n",
      "             |     0.013 |     0.000 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          24 |         1 |         1 |         2 | \n",
      "             |     0.026 |     0.020 |           | \n",
      "             |     0.500 |     0.500 |     0.025 | \n",
      "             |     0.029 |     0.022 |           | \n",
      "             |     0.013 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          25 |         5 |         2 |         7 | \n",
      "             |     1.378 |     1.019 |           | \n",
      "             |     0.714 |     0.286 |     0.087 | \n",
      "             |     0.147 |     0.043 |           | \n",
      "             |     0.062 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          26 |         6 |         4 |        10 | \n",
      "             |     0.721 |     0.533 |           | \n",
      "             |     0.600 |     0.400 |     0.125 | \n",
      "             |     0.176 |     0.087 |           | \n",
      "             |     0.075 |     0.050 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          27 |         3 |         4 |         7 | \n",
      "             |     0.000 |     0.000 |           | \n",
      "             |     0.429 |     0.571 |     0.087 | \n",
      "             |     0.088 |     0.087 |           | \n",
      "             |     0.037 |     0.050 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          28 |         3 |         3 |         6 | \n",
      "             |     0.079 |     0.059 |           | \n",
      "             |     0.500 |     0.500 |     0.075 | \n",
      "             |     0.088 |     0.065 |           | \n",
      "             |     0.037 |     0.037 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          29 |         1 |         5 |         6 | \n",
      "             |     0.942 |     0.696 |           | \n",
      "             |     0.167 |     0.833 |     0.075 | \n",
      "             |     0.029 |     0.109 |           | \n",
      "             |     0.013 |     0.062 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          30 |         2 |         1 |         3 | \n",
      "             |     0.412 |     0.305 |           | \n",
      "             |     0.667 |     0.333 |     0.037 | \n",
      "             |     0.059 |     0.022 |           | \n",
      "             |     0.025 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          31 |         3 |         0 |         3 | \n",
      "             |     2.334 |     1.725 |           | \n",
      "             |     1.000 |     0.000 |     0.037 | \n",
      "             |     0.088 |     0.000 |           | \n",
      "             |     0.037 |     0.000 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          32 |         1 |         7 |         8 | \n",
      "             |     1.694 |     1.252 |           | \n",
      "             |     0.125 |     0.875 |     0.100 | \n",
      "             |     0.029 |     0.152 |           | \n",
      "             |     0.013 |     0.087 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          33 |         2 |         3 |         5 | \n",
      "             |     0.007 |     0.005 |           | \n",
      "             |     0.400 |     0.600 |     0.062 | \n",
      "             |     0.059 |     0.065 |           | \n",
      "             |     0.025 |     0.037 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          35 |         1 |         1 |         2 | \n",
      "             |     0.026 |     0.020 |           | \n",
      "             |     0.500 |     0.500 |     0.025 | \n",
      "             |     0.029 |     0.022 |           | \n",
      "             |     0.013 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          36 |         1 |         2 |         3 | \n",
      "             |     0.059 |     0.044 |           | \n",
      "             |     0.333 |     0.667 |     0.037 | \n",
      "             |     0.029 |     0.043 |           | \n",
      "             |     0.013 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          37 |         0 |         1 |         1 | \n",
      "             |     0.425 |     0.314 |           | \n",
      "             |     0.000 |     1.000 |     0.013 | \n",
      "             |     0.000 |     0.022 |           | \n",
      "             |     0.000 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          38 |         0 |         1 |         1 | \n",
      "             |     0.425 |     0.314 |           | \n",
      "             |     0.000 |     1.000 |     0.013 | \n",
      "             |     0.000 |     0.022 |           | \n",
      "             |     0.000 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "          40 |         0 |         1 |         1 | \n",
      "             |     0.425 |     0.314 |           | \n",
      "             |     0.000 |     1.000 |     0.013 | \n",
      "             |     0.000 |     0.022 |           | \n",
      "             |     0.000 |     0.013 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      "  rawdata$DN |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           1 |        19 |        22 |        41 | \n",
      "             |     0.142 |     0.105 |           | \n",
      "             |     0.463 |     0.537 |     0.512 | \n",
      "             |     0.559 |     0.478 |           | \n",
      "             |     0.237 |     0.275 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           2 |        12 |        15 |        27 | \n",
      "             |     0.024 |     0.018 |           | \n",
      "             |     0.444 |     0.556 |     0.338 | \n",
      "             |     0.353 |     0.326 |           | \n",
      "             |     0.150 |     0.188 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           3 |         3 |         7 |        10 | \n",
      "             |     0.368 |     0.272 |           | \n",
      "             |     0.300 |     0.700 |     0.125 | \n",
      "             |     0.088 |     0.152 |           | \n",
      "             |     0.037 |     0.087 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           4 |         0 |         2 |         2 | \n",
      "             |     0.850 |     0.628 |           | \n",
      "             |     0.000 |     1.000 |     0.025 | \n",
      "             |     0.000 |     0.043 |           | \n",
      "             |     0.000 |     0.025 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      "  rawdata$DT |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           0 |        16 |        30 |        46 | \n",
      "             |     0.645 |     0.476 |           | \n",
      "             |     0.348 |     0.652 |     0.575 | \n",
      "             |     0.471 |     0.652 |           | \n",
      "             |     0.200 |     0.375 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           1 |         9 |         8 |        17 | \n",
      "             |     0.436 |     0.322 |           | \n",
      "             |     0.529 |     0.471 |     0.212 | \n",
      "             |     0.265 |     0.174 |           | \n",
      "             |     0.113 |     0.100 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           2 |         9 |         8 |        17 | \n",
      "             |     0.436 |     0.322 |           | \n",
      "             |     0.529 |     0.471 |     0.212 | \n",
      "             |     0.265 |     0.174 |           | \n",
      "             |     0.113 |     0.100 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      "  rawdata$BP |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           0 |         5 |        15 |        20 | \n",
      "             |     1.441 |     1.065 |           | \n",
      "             |     0.250 |     0.750 |     0.250 | \n",
      "             |     0.147 |     0.326 |           | \n",
      "             |     0.062 |     0.188 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           1 |        23 |        17 |        40 | \n",
      "             |     2.118 |     1.565 |           | \n",
      "             |     0.575 |     0.425 |     0.500 | \n",
      "             |     0.676 |     0.370 |           | \n",
      "             |     0.287 |     0.212 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           2 |         6 |        14 |        20 | \n",
      "             |     0.735 |     0.543 |           | \n",
      "             |     0.300 |     0.700 |     0.250 | \n",
      "             |     0.176 |     0.304 |           | \n",
      "             |     0.075 |     0.175 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      "  rawdata$HP |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           0 |        28 |        22 |        50 | \n",
      "             |     2.144 |     1.585 |           | \n",
      "             |     0.560 |     0.440 |     0.625 | \n",
      "             |     0.824 |     0.478 |           | \n",
      "             |     0.350 |     0.275 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           1 |         6 |        24 |        30 | \n",
      "             |     3.574 |     2.641 |           | \n",
      "             |     0.200 |     0.800 |     0.375 | \n",
      "             |     0.176 |     0.522 |           | \n",
      "             |     0.075 |     0.300 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## cross-tab\n",
    "#install.packages(\"gmodels\")\n",
    "library(gmodels)\n",
    "#cons = rawdata$CS %in% 1\n",
    "CrossTable(x=rawdata$Age, y=rawdata$CS)\n",
    "CrossTable(x=rawdata$DN, y=rawdata$CS)\n",
    "CrossTable(x=rawdata$DT, y=rawdata$CS)\n",
    "CrossTable(x=rawdata$BP, y=rawdata$CS)\n",
    "CrossTable(x=rawdata$HP, y=rawdata$CS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  80 \n",
      "\n",
      " \n",
      "             | rawdata$CS \n",
      "  rawdata$HP |         0 |         1 | Row Total | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           0 |        28 |        22 |        50 | \n",
      "             |     2.144 |     1.585 |           | \n",
      "             |     0.560 |     0.440 |     0.625 | \n",
      "             |     0.824 |     0.478 |           | \n",
      "             |     0.350 |     0.275 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "           1 |         6 |        24 |        30 | \n",
      "             |     3.574 |     2.641 |           | \n",
      "             |     0.200 |     0.800 |     0.375 | \n",
      "             |     0.176 |     0.522 |           | \n",
      "             |     0.075 |     0.300 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "Column Total |        34 |        46 |        80 | \n",
      "             |     0.425 |     0.575 |           | \n",
      "-------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$t\n",
       "   y\n",
       "x    0  1\n",
       "  0 28 22\n",
       "  1  6 24\n",
       "\n",
       "$prop.row\n",
       "   y\n",
       "x      0    1\n",
       "  0 0.56 0.44\n",
       "  1 0.20 0.80\n",
       "\n",
       "$prop.col\n",
       "   y\n",
       "x           0         1\n",
       "  0 0.8235294 0.4782609\n",
       "  1 0.1764706 0.5217391\n",
       "\n",
       "$prop.tbl\n",
       "   y\n",
       "x       0     1\n",
       "  0 0.350 0.275\n",
       "  1 0.075 0.300\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   y\n",
       "x    0  1\n",
       "  0 28 22\n",
       "  1  6 24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'table' int [1:2, 1:2] 28 6 22 24\n",
      " - attr(*, \"dimnames\")=List of 2\n",
      "  ..$ x: chr [1:2] \"0\" \"1\"\n",
      "  ..$ y: chr [1:2] \"0\" \"1\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>0</dt>\n",
       "\t\t<dd>28</dd>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>6</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 28\n",
       "\\item[1] 6\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   281\n",
       ":   6\n",
       "\n"
      ],
      "text/plain": [
       " 0  1 \n",
       "28  6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>y</th><th scope=col>Freq</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0 </td><td>0 </td><td>28</td></tr>\n",
       "\t<tr><td>1 </td><td>0 </td><td> 6</td></tr>\n",
       "\t<tr><td>0 </td><td>1 </td><td>22</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " x & y & Freq\\\\\n",
       "\\hline\n",
       "\t 0  & 0  & 28\\\\\n",
       "\t 1  & 0  &  6\\\\\n",
       "\t 0  & 1  & 22\\\\\n",
       "\t 1  & 1  & 24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x | y | Freq | \n",
       "|---|---|---|---|\n",
       "| 0  | 0  | 28 | \n",
       "| 1  | 0  |  6 | \n",
       "| 0  | 1  | 22 | \n",
       "| 1  | 1  | 24 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x y Freq\n",
       "1 0 0 28  \n",
       "2 1 0  6  \n",
       "3 0 1 22  \n",
       "4 1 1 24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'0'</li>\n",
       "\t\t<li>'1'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 0\n",
       "4. 1\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 1 0 1\n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=CrossTable(x=rawdata$HP, y=rawdata$CS)\n",
    "a\n",
    "b=a$t\n",
    "b\n",
    "str(b)\n",
    "b[,1]\n",
    "c=as.data.frame(b)\n",
    "c\n",
    "c[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrplot 0.84 loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n",
      "'data.frame':\t80 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 12 6 10 11 16 12 11 ...\n",
      " $ DN : num  1 2 2 1 2 1 2 3 2 1 ...\n",
      " $ DT : num  1 1 2 1 1 2 1 1 1 2 ...\n",
      " $ BP : num  3 2 2 3 2 1 2 2 2 2 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 2 1 2 ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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",
      "text/plain": [
       "Plot with title “”"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check collinearity btw features\n",
    "library(corrplot)\n",
    "str(rawdata)\n",
    "rawdata.num=rawdata\n",
    "for ( i in 1:5)  { rawdata.num[,i] = as.numeric(rawdata[,i]) }\n",
    "str(rawdata.num)\n",
    "\n",
    "rawdata.cor = cor(rawdata.num[,1:5])\n",
    "corrplot.mixed(rawdata.cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n",
      "'data.frame':\t24 obs. of  6 variables:\n",
      " $ Age: Factor w/ 22 levels \"17\",\"18\",\"19\",..: 10 12 6 16 19 9 8 10 11 2 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 2 1 2 3 1 1 1 1 1 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 1 1 1 3 3 2 1 1 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 2 3 2 2 2 1 1 2 1 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 2 1 2 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 2 1 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "##sample from category data\n",
    "\n",
    "## dividing orginal data by ratio for tran, test\n",
    "\n",
    "#fix random seed\n",
    "set.seed(123)\n",
    "\n",
    "# make index vector(row number) for two type(x=2 : train, test) of samples \n",
    "# with probability weight : train:test = 7:3  \n",
    "# in number of sample=nrow(rawdata3)=80 )\n",
    "# replace : If TRUE, same data from orginal can be repeat in new sample\n",
    "ind = sample(2, nrow(rawdata), replace=TRUE, prob=c(0.7,0.3))\n",
    "\n",
    "traindata = rawdata[ind==1,] \n",
    "str(traindata) ## 80datas * 70% = 56datas\n",
    "testdata = rawdata[ind==2,] \n",
    "str(testdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = CS ~ ., family = binomial, data = traindata)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.59745  -0.63593   0.00008   0.52251   2.16410  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept)    18.1152 10754.0134   0.002    0.999\n",
       "Age19           2.5219 13170.9225   0.000    1.000\n",
       "Age20         -18.5369 10754.0133  -0.002    0.999\n",
       "Age21           1.2923 15208.4713   0.000    1.000\n",
       "Age22         -19.2847 10754.0134  -0.002    0.999\n",
       "Age23         -36.1258 15208.4712  -0.002    0.998\n",
       "Age24         -36.6685 15208.4713  -0.002    0.998\n",
       "Age25         -18.9575 10754.0134  -0.002    0.999\n",
       "Age26         -18.5102 10754.0134  -0.002    0.999\n",
       "Age27         -17.8462 10754.0134  -0.002    0.999\n",
       "Age28         -15.3920 10754.0136  -0.001    0.999\n",
       "Age29           1.1300 11788.4886   0.000    1.000\n",
       "Age30         -17.9533 10754.0134  -0.002    0.999\n",
       "Age31         -36.6389 13169.0009  -0.003    0.998\n",
       "Age32         -15.5089 10754.0135  -0.001    0.999\n",
       "Age33         -16.8293 10754.0134  -0.002    0.999\n",
       "Age35         -16.9856 10754.0135  -0.002    0.999\n",
       "Age36           0.2508 12421.8998   0.000    1.000\n",
       "Age37           3.7536 15208.4714   0.000    1.000\n",
       "Age38           1.3321 15208.4713   0.000    1.000\n",
       "DN2            -0.7036     1.2665  -0.556    0.578\n",
       "DN3            -2.5784     2.2279  -1.157    0.247\n",
       "DN4            18.2553  6217.2982   0.003    0.998\n",
       "DT1            -0.4845     1.2254  -0.395    0.693\n",
       "DT2             0.7618     1.3390   0.569    0.569\n",
       "BP1            -1.0710     1.2678  -0.845    0.398\n",
       "BP2             0.5886     1.5229   0.387    0.699\n",
       "HP1             1.3467     1.1768   1.144    0.252\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 38.664  on 28  degrees of freedom\n",
       "AIC: 94.664\n",
       "\n",
       "Number of Fisher Scoring iterations: 18\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data\n",
    "full.fit = glm(CS~., family=binomial, data=traindata)\n",
    "summary(full.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for profiling to be done...\n",
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-2.094650e+03</td><td>         NA  </td></tr>\n",
       "\t<tr><th scope=row>Age19</th><td>-9.573072e+02</td><td>         NA  </td></tr>\n",
       "\t<tr><th scope=row>Age20</th><td>           NA</td><td>2149.076458  </td></tr>\n",
       "\t<tr><th scope=row>Age21</th><td>-1.050708e+03</td><td>7136.888690  </td></tr>\n",
       "\t<tr><th scope=row>Age22</th><td>           NA</td><td>2133.847798  </td></tr>\n",
       "\t<tr><th scope=row>Age23</th><td>           NA</td><td>3025.698526  </td></tr>\n",
       "\t<tr><th scope=row>Age24</th><td>           NA</td><td>2154.609943  </td></tr>\n",
       "\t<tr><th scope=row>Age25</th><td>           NA</td><td>2127.019756  </td></tr>\n",
       "\t<tr><th scope=row>Age26</th><td>           NA</td><td>2093.017957  </td></tr>\n",
       "\t<tr><th scope=row>Age27</th><td>           NA</td><td>2022.884439  </td></tr>\n",
       "\t<tr><th scope=row>Age28</th><td>           NA</td><td> 798.342314  </td></tr>\n",
       "\t<tr><th scope=row>Age29</th><td>-2.328225e+03</td><td>         NA  </td></tr>\n",
       "\t<tr><th scope=row>Age30</th><td>           NA</td><td>1636.408477  </td></tr>\n",
       "\t<tr><th scope=row>Age31</th><td>           NA</td><td>1678.801780  </td></tr>\n",
       "\t<tr><th scope=row>Age32</th><td>           NA</td><td> 741.320049  </td></tr>\n",
       "\t<tr><th scope=row>Age33</th><td>           NA</td><td> 713.708954  </td></tr>\n",
       "\t<tr><th scope=row>Age35</th><td>           NA</td><td>1078.977372  </td></tr>\n",
       "\t<tr><th scope=row>Age36</th><td>-8.632155e+02</td><td>         NA  </td></tr>\n",
       "\t<tr><th scope=row>Age37</th><td>-3.429248e+03</td><td>-968.099687  </td></tr>\n",
       "\t<tr><th scope=row>Age38</th><td>-1.196260e+04</td><td>2133.078736  </td></tr>\n",
       "\t<tr><th scope=row>DN2</th><td>-3.425295e+00</td><td>   1.786634  </td></tr>\n",
       "\t<tr><th scope=row>DN3</th><td>-7.673610e+00</td><td>   1.516972  </td></tr>\n",
       "\t<tr><th scope=row>DN4</th><td>-7.938026e+02</td><td>         NA  </td></tr>\n",
       "\t<tr><th scope=row>DT1</th><td>-3.084138e+00</td><td>   1.895982  </td></tr>\n",
       "\t<tr><th scope=row>DT2</th><td>-1.892426e+00</td><td>   3.513395  </td></tr>\n",
       "\t<tr><th scope=row>BP1</th><td>-3.772956e+00</td><td>   1.408784  </td></tr>\n",
       "\t<tr><th scope=row>BP2</th><td>-2.338303e+00</td><td>   3.861252  </td></tr>\n",
       "\t<tr><th scope=row>HP1</th><td>-9.135208e-01</td><td>   3.962845  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -2.094650e+03 &          NA  \\\\\n",
       "\tAge19 & -9.573072e+02 &          NA  \\\\\n",
       "\tAge20 &            NA & 2149.076458  \\\\\n",
       "\tAge21 & -1.050708e+03 & 7136.888690  \\\\\n",
       "\tAge22 &            NA & 2133.847798  \\\\\n",
       "\tAge23 &            NA & 3025.698526  \\\\\n",
       "\tAge24 &            NA & 2154.609943  \\\\\n",
       "\tAge25 &            NA & 2127.019756  \\\\\n",
       "\tAge26 &            NA & 2093.017957  \\\\\n",
       "\tAge27 &            NA & 2022.884439  \\\\\n",
       "\tAge28 &            NA &  798.342314  \\\\\n",
       "\tAge29 & -2.328225e+03 &          NA  \\\\\n",
       "\tAge30 &            NA & 1636.408477  \\\\\n",
       "\tAge31 &            NA & 1678.801780  \\\\\n",
       "\tAge32 &            NA &  741.320049  \\\\\n",
       "\tAge33 &            NA &  713.708954  \\\\\n",
       "\tAge35 &            NA & 1078.977372  \\\\\n",
       "\tAge36 & -8.632155e+02 &          NA  \\\\\n",
       "\tAge37 & -3.429248e+03 & -968.099687  \\\\\n",
       "\tAge38 & -1.196260e+04 & 2133.078736  \\\\\n",
       "\tDN2 & -3.425295e+00 &    1.786634  \\\\\n",
       "\tDN3 & -7.673610e+00 &    1.516972  \\\\\n",
       "\tDN4 & -7.938026e+02 &          NA  \\\\\n",
       "\tDT1 & -3.084138e+00 &    1.895982  \\\\\n",
       "\tDT2 & -1.892426e+00 &    3.513395  \\\\\n",
       "\tBP1 & -3.772956e+00 &    1.408784  \\\\\n",
       "\tBP2 & -2.338303e+00 &    3.861252  \\\\\n",
       "\tHP1 & -9.135208e-01 &    3.962845  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| (Intercept) | -2.094650e+03 |          NA   | \n",
       "| Age19 | -9.573072e+02 |          NA   | \n",
       "| Age20 |            NA | 2149.076458   | \n",
       "| Age21 | -1.050708e+03 | 7136.888690   | \n",
       "| Age22 |            NA | 2133.847798   | \n",
       "| Age23 |            NA | 3025.698526   | \n",
       "| Age24 |            NA | 2154.609943   | \n",
       "| Age25 |            NA | 2127.019756   | \n",
       "| Age26 |            NA | 2093.017957   | \n",
       "| Age27 |            NA | 2022.884439   | \n",
       "| Age28 |            NA |  798.342314   | \n",
       "| Age29 | -2.328225e+03 |          NA   | \n",
       "| Age30 |            NA | 1636.408477   | \n",
       "| Age31 |            NA | 1678.801780   | \n",
       "| Age32 |            NA |  741.320049   | \n",
       "| Age33 |            NA |  713.708954   | \n",
       "| Age35 |            NA | 1078.977372   | \n",
       "| Age36 | -8.632155e+02 |          NA   | \n",
       "| Age37 | -3.429248e+03 | -968.099687   | \n",
       "| Age38 | -1.196260e+04 | 2133.078736   | \n",
       "| DN2 | -3.425295e+00 |    1.786634   | \n",
       "| DN3 | -7.673610e+00 |    1.516972   | \n",
       "| DN4 | -7.938026e+02 |          NA   | \n",
       "| DT1 | -3.084138e+00 |    1.895982   | \n",
       "| DT2 | -1.892426e+00 |    3.513395   | \n",
       "| BP1 | -3.772956e+00 |    1.408784   | \n",
       "| BP2 | -2.338303e+00 |    3.861252   | \n",
       "| HP1 | -9.135208e-01 |    3.962845   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %         97.5 %     \n",
       "(Intercept) -2.094650e+03          NA\n",
       "Age19       -9.573072e+02          NA\n",
       "Age20                  NA 2149.076458\n",
       "Age21       -1.050708e+03 7136.888690\n",
       "Age22                  NA 2133.847798\n",
       "Age23                  NA 3025.698526\n",
       "Age24                  NA 2154.609943\n",
       "Age25                  NA 2127.019756\n",
       "Age26                  NA 2093.017957\n",
       "Age27                  NA 2022.884439\n",
       "Age28                  NA  798.342314\n",
       "Age29       -2.328225e+03          NA\n",
       "Age30                  NA 1636.408477\n",
       "Age31                  NA 1678.801780\n",
       "Age32                  NA  741.320049\n",
       "Age33                  NA  713.708954\n",
       "Age35                  NA 1078.977372\n",
       "Age36       -8.632155e+02          NA\n",
       "Age37       -3.429248e+03 -968.099687\n",
       "Age38       -1.196260e+04 2133.078736\n",
       "DN2         -3.425295e+00    1.786634\n",
       "DN3         -7.673610e+00    1.516972\n",
       "DN4         -7.938026e+02          NA\n",
       "DT1         -3.084138e+00    1.895982\n",
       "DT2         -1.892426e+00    3.513395\n",
       "BP1         -3.772956e+00    1.408784\n",
       "BP2         -2.338303e+00    3.861252\n",
       "HP1         -9.135208e-01    3.962845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>73676477.7645909</dd>\n",
       "\t<dt>Age19</dt>\n",
       "\t\t<dd>12.4520057700714</dd>\n",
       "\t<dt>Age20</dt>\n",
       "\t\t<dd>8.90300769979074e-09</dd>\n",
       "\t<dt>Age21</dt>\n",
       "\t\t<dd>3.64104048768724</dd>\n",
       "\t<dt>Age22</dt>\n",
       "\t\t<dd>4.21447377505875e-09</dd>\n",
       "\t<dt>Age23</dt>\n",
       "\t\t<dd>2.04534269835895e-16</dd>\n",
       "\t<dt>Age24</dt>\n",
       "\t\t<dd>1.18874265140111e-16</dd>\n",
       "\t<dt>Age25</dt>\n",
       "\t\t<dd>5.84628944710208e-09</dd>\n",
       "\t<dt>Age26</dt>\n",
       "\t\t<dd>9.14413543502887e-09</dd>\n",
       "\t<dt>Age27</dt>\n",
       "\t\t<dd>1.77621537112921e-08</dd>\n",
       "\t<dt>Age28</dt>\n",
       "\t\t<dd>2.0670430065624e-07</dd>\n",
       "\t<dt>Age29</dt>\n",
       "\t\t<dd>3.0956858968133</dd>\n",
       "\t<dt>Age30</dt>\n",
       "\t\t<dd>1.59579324891111e-08</dd>\n",
       "\t<dt>Age31</dt>\n",
       "\t\t<dd>1.2244030242751e-16</dd>\n",
       "\t<dt>Age32</dt>\n",
       "\t\t<dd>1.83891911239e-07</dd>\n",
       "\t<dt>Age33</dt>\n",
       "\t\t<dd>4.91036257483744e-08</dd>\n",
       "\t<dt>Age35</dt>\n",
       "\t\t<dd>4.1998035259231e-08</dd>\n",
       "\t<dt>Age36</dt>\n",
       "\t\t<dd>1.28506922750348</dd>\n",
       "\t<dt>Age37</dt>\n",
       "\t\t<dd>42.673278446684</dd>\n",
       "\t<dt>Age38</dt>\n",
       "\t\t<dd>3.78893899791132</dd>\n",
       "\t<dt>DN2</dt>\n",
       "\t\t<dd>0.494783116480694</dd>\n",
       "\t<dt>DN3</dt>\n",
       "\t\t<dd>0.0758960201736215</dd>\n",
       "\t<dt>DN4</dt>\n",
       "\t\t<dd>84759422.9979446</dd>\n",
       "\t<dt>DT1</dt>\n",
       "\t\t<dd>0.616030267291148</dd>\n",
       "\t<dt>DT2</dt>\n",
       "\t\t<dd>2.14222665385163</dd>\n",
       "\t<dt>BP1</dt>\n",
       "\t\t<dd>0.342663162605291</dd>\n",
       "\t<dt>BP2</dt>\n",
       "\t\t<dd>1.80152542911072</dd>\n",
       "\t<dt>HP1</dt>\n",
       "\t\t<dd>3.84471634569011</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 73676477.7645909\n",
       "\\item[Age19] 12.4520057700714\n",
       "\\item[Age20] 8.90300769979074e-09\n",
       "\\item[Age21] 3.64104048768724\n",
       "\\item[Age22] 4.21447377505875e-09\n",
       "\\item[Age23] 2.04534269835895e-16\n",
       "\\item[Age24] 1.18874265140111e-16\n",
       "\\item[Age25] 5.84628944710208e-09\n",
       "\\item[Age26] 9.14413543502887e-09\n",
       "\\item[Age27] 1.77621537112921e-08\n",
       "\\item[Age28] 2.0670430065624e-07\n",
       "\\item[Age29] 3.0956858968133\n",
       "\\item[Age30] 1.59579324891111e-08\n",
       "\\item[Age31] 1.2244030242751e-16\n",
       "\\item[Age32] 1.83891911239e-07\n",
       "\\item[Age33] 4.91036257483744e-08\n",
       "\\item[Age35] 4.1998035259231e-08\n",
       "\\item[Age36] 1.28506922750348\n",
       "\\item[Age37] 42.673278446684\n",
       "\\item[Age38] 3.78893899791132\n",
       "\\item[DN2] 0.494783116480694\n",
       "\\item[DN3] 0.0758960201736215\n",
       "\\item[DN4] 84759422.9979446\n",
       "\\item[DT1] 0.616030267291148\n",
       "\\item[DT2] 2.14222665385163\n",
       "\\item[BP1] 0.342663162605291\n",
       "\\item[BP2] 1.80152542911072\n",
       "\\item[HP1] 3.84471634569011\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   73676477.7645909Age19\n",
       ":   12.4520057700714Age20\n",
       ":   8.90300769979074e-09Age21\n",
       ":   3.64104048768724Age22\n",
       ":   4.21447377505875e-09Age23\n",
       ":   2.04534269835895e-16Age24\n",
       ":   1.18874265140111e-16Age25\n",
       ":   5.84628944710208e-09Age26\n",
       ":   9.14413543502887e-09Age27\n",
       ":   1.77621537112921e-08Age28\n",
       ":   2.0670430065624e-07Age29\n",
       ":   3.0956858968133Age30\n",
       ":   1.59579324891111e-08Age31\n",
       ":   1.2244030242751e-16Age32\n",
       ":   1.83891911239e-07Age33\n",
       ":   4.91036257483744e-08Age35\n",
       ":   4.1998035259231e-08Age36\n",
       ":   1.28506922750348Age37\n",
       ":   42.673278446684Age38\n",
       ":   3.78893899791132DN2\n",
       ":   0.494783116480694DN3\n",
       ":   0.0758960201736215DN4\n",
       ":   84759422.9979446DT1\n",
       ":   0.616030267291148DT2\n",
       ":   2.14222665385163BP1\n",
       ":   0.342663162605291BP2\n",
       ":   1.80152542911072HP1\n",
       ":   3.84471634569011\n",
       "\n"
      ],
      "text/plain": [
       " (Intercept)        Age19        Age20        Age21        Age22        Age23 \n",
       "7.367648e+07 1.245201e+01 8.903008e-09 3.641040e+00 4.214474e-09 2.045343e-16 \n",
       "       Age24        Age25        Age26        Age27        Age28        Age29 \n",
       "1.188743e-16 5.846289e-09 9.144135e-09 1.776215e-08 2.067043e-07 3.095686e+00 \n",
       "       Age30        Age31        Age32        Age33        Age35        Age36 \n",
       "1.595793e-08 1.224403e-16 1.838919e-07 4.910363e-08 4.199804e-08 1.285069e+00 \n",
       "       Age37        Age38          DN2          DN3          DN4          DT1 \n",
       "4.267328e+01 3.788939e+00 4.947831e-01 7.589602e-02 8.475942e+07 6.160303e-01 \n",
       "         DT2          BP1          BP2          HP1 \n",
       "2.142227e+00 3.426632e-01 1.801525e+00 3.844716e+00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confint(full.fit)\n",
    "exp(coef(full.fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>GVIF</th><th scope=col>Df</th><th scope=col>GVIF^(1/(2*Df))</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Age</th><td>19.514940</td><td>19       </td><td>1.081327 </td></tr>\n",
       "\t<tr><th scope=row>DN</th><td> 5.815875</td><td> 3       </td><td>1.341022 </td></tr>\n",
       "\t<tr><th scope=row>DT</th><td> 2.678911</td><td> 2       </td><td>1.279351 </td></tr>\n",
       "\t<tr><th scope=row>BP</th><td> 3.088776</td><td> 2       </td><td>1.325704 </td></tr>\n",
       "\t<tr><th scope=row>HP</th><td> 1.989140</td><td> 1       </td><td>1.410369 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & GVIF & Df & GVIF\\textasciicircum{}(1/(2*Df))\\\\\n",
       "\\hline\n",
       "\tAge & 19.514940 & 19        & 1.081327 \\\\\n",
       "\tDN &  5.815875 &  3        & 1.341022 \\\\\n",
       "\tDT &  2.678911 &  2        & 1.279351 \\\\\n",
       "\tBP &  3.088776 &  2        & 1.325704 \\\\\n",
       "\tHP &  1.989140 &  1        & 1.410369 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | GVIF | Df | GVIF^(1/(2*Df)) | \n",
       "|---|---|---|---|---|\n",
       "| Age | 19.514940 | 19        | 1.081327  | \n",
       "| DN |  5.815875 |  3        | 1.341022  | \n",
       "| DT |  2.678911 |  2        | 1.279351  | \n",
       "| BP |  3.088776 |  2        | 1.325704  | \n",
       "| HP |  1.989140 |  1        | 1.410369  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    GVIF      Df GVIF^(1/(2*Df))\n",
       "Age 19.514940 19 1.081327       \n",
       "DN   5.815875  3 1.341022       \n",
       "DT   2.678911  2 1.279351       \n",
       "BP   3.088776  2 1.325704       \n",
       "HP   1.989140  1 1.410369       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(car)\n",
    "vif(full.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : num  1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : num  1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : num  3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : num  1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n",
      "'data.frame':\t24 obs. of  6 variables:\n",
      " $ Age: num  10 12 6 16 19 9 8 10 11 2 ...\n",
      " $ DN : num  2 1 2 3 1 1 1 1 1 1 ...\n",
      " $ DT : num  1 1 1 1 1 3 3 2 1 1 ...\n",
      " $ BP : num  2 3 2 2 2 1 1 2 1 2 ...\n",
      " $ HP : num  1 1 1 1 1 1 2 1 2 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 2 1 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "## log reg from numeric data\n",
    "\n",
    "traindata.num = rawdata.num[ind==1,] \n",
    "str(traindata.num) ## 80datas * 70% = 56datas\n",
    "testdata.num = rawdata.num[ind==2,] \n",
    "str(testdata.num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = CS ~ ., family = binomial, data = traindata.num)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9359  -1.0293   0.5149   0.8963   1.5201  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept) -2.78921    1.76248  -1.583  0.11353   \n",
       "Age          0.05993    0.07465   0.803  0.42208   \n",
       "DN          -0.13158    0.44714  -0.294  0.76856   \n",
       "DT          -0.14475    0.38001  -0.381  0.70327   \n",
       "BP           0.24278    0.45556   0.533  0.59409   \n",
       "HP           1.79571    0.67783   2.649  0.00807 **\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 65.160  on 50  degrees of freedom\n",
       "AIC: 77.16\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data (numeric type)\n",
    "full.fit_num = glm(CS~., family=binomial, data=traindata.num)\n",
    "summary(full.fit_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for profiling to be done...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-6.52697337</td><td>0.4877489  </td></tr>\n",
       "\t<tr><th scope=row>Age</th><td>-0.08732483</td><td>0.2112889  </td></tr>\n",
       "\t<tr><th scope=row>DN</th><td>-1.03231225</td><td>0.7578197  </td></tr>\n",
       "\t<tr><th scope=row>DT</th><td>-0.90278716</td><td>0.6074640  </td></tr>\n",
       "\t<tr><th scope=row>BP</th><td>-0.65111496</td><td>1.1662917  </td></tr>\n",
       "\t<tr><th scope=row>HP</th><td> 0.53867485</td><td>3.2457265  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -6.52697337 & 0.4877489  \\\\\n",
       "\tAge & -0.08732483 & 0.2112889  \\\\\n",
       "\tDN & -1.03231225 & 0.7578197  \\\\\n",
       "\tDT & -0.90278716 & 0.6074640  \\\\\n",
       "\tBP & -0.65111496 & 1.1662917  \\\\\n",
       "\tHP &  0.53867485 & 3.2457265  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|---|---|---|---|---|\n",
       "| (Intercept) | -6.52697337 | 0.4877489   | \n",
       "| Age | -0.08732483 | 0.2112889   | \n",
       "| DN | -1.03231225 | 0.7578197   | \n",
       "| DT | -0.90278716 | 0.6074640   | \n",
       "| BP | -0.65111496 | 1.1662917   | \n",
       "| HP |  0.53867485 | 3.2457265   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %       97.5 %   \n",
       "(Intercept) -6.52697337 0.4877489\n",
       "Age         -0.08732483 0.2112889\n",
       "DN          -1.03231225 0.7578197\n",
       "DT          -0.90278716 0.6074640\n",
       "BP          -0.65111496 1.1662917\n",
       "HP           0.53867485 3.2457265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.0614699983020103</dd>\n",
       "\t<dt>Age</dt>\n",
       "\t\t<dd>1.06176467162423</dd>\n",
       "\t<dt>DN</dt>\n",
       "\t\t<dd>0.876713446845346</dd>\n",
       "\t<dt>DT</dt>\n",
       "\t\t<dd>0.865241464773045</dd>\n",
       "\t<dt>BP</dt>\n",
       "\t\t<dd>1.27478659375149</dd>\n",
       "\t<dt>HP</dt>\n",
       "\t\t<dd>6.02374908760084</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.0614699983020103\n",
       "\\item[Age] 1.06176467162423\n",
       "\\item[DN] 0.876713446845346\n",
       "\\item[DT] 0.865241464773045\n",
       "\\item[BP] 1.27478659375149\n",
       "\\item[HP] 6.02374908760084\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.0614699983020103Age\n",
       ":   1.06176467162423DN\n",
       ":   0.876713446845346DT\n",
       ":   0.865241464773045BP\n",
       ":   1.27478659375149HP\n",
       ":   6.02374908760084\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)         Age          DN          DT          BP          HP \n",
       "  0.0614700   1.0617647   0.8767134   0.8652415   1.2747866   6.0237491 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confint(full.fit_num)\n",
    "exp(coef(full.fit_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>GVIF</th><th scope=col>Df</th><th scope=col>GVIF^(1/(2*Df))</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Age</th><td>19.514940</td><td>19       </td><td>1.081327 </td></tr>\n",
       "\t<tr><th scope=row>DN</th><td> 5.815875</td><td> 3       </td><td>1.341022 </td></tr>\n",
       "\t<tr><th scope=row>DT</th><td> 2.678911</td><td> 2       </td><td>1.279351 </td></tr>\n",
       "\t<tr><th scope=row>BP</th><td> 3.088776</td><td> 2       </td><td>1.325704 </td></tr>\n",
       "\t<tr><th scope=row>HP</th><td> 1.989140</td><td> 1       </td><td>1.410369 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & GVIF & Df & GVIF\\textasciicircum{}(1/(2*Df))\\\\\n",
       "\\hline\n",
       "\tAge & 19.514940 & 19        & 1.081327 \\\\\n",
       "\tDN &  5.815875 &  3        & 1.341022 \\\\\n",
       "\tDT &  2.678911 &  2        & 1.279351 \\\\\n",
       "\tBP &  3.088776 &  2        & 1.325704 \\\\\n",
       "\tHP &  1.989140 &  1        & 1.410369 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | GVIF | Df | GVIF^(1/(2*Df)) | \n",
       "|---|---|---|---|---|\n",
       "| Age | 19.514940 | 19        | 1.081327  | \n",
       "| DN |  5.815875 |  3        | 1.341022  | \n",
       "| DT |  2.678911 |  2        | 1.279351  | \n",
       "| BP |  3.088776 |  2        | 1.325704  | \n",
       "| HP |  1.989140 |  1        | 1.410369  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    GVIF      Df GVIF^(1/(2*Df))\n",
       "Age 19.514940 19 1.081327       \n",
       "DN   5.815875  3 1.341022       \n",
       "DT   2.678911  2 1.279351       \n",
       "BP   3.088776  2 1.325704       \n",
       "HP   1.989140  1 1.410369       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vif(full.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n",
      "'data.frame':\t24 obs. of  6 variables:\n",
      " $ Age: num  10 12 6 16 19 9 8 10 11 2 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 2 1 2 3 1 1 1 1 1 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 1 1 1 3 3 2 1 1 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 2 3 2 2 2 1 1 2 1 2 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 2 1 2 1 ...\n",
      " $ CS : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 2 1 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "# log reg from only numeric about Age\n",
    "\n",
    "#copy data for pre-processing \n",
    "rawdata.num_age=rawdata\n",
    "\n",
    "#change type for numeric data column=Age,DN(Delivery Number)\n",
    "rawdata.num_age$Age=as.numeric(rawdata$Age)\n",
    "#rawdata2$DN=as.numeric(rawdata$DN)\n",
    "\n",
    "traindata.num_age = rawdata.num_age[ind==1,] \n",
    "str(traindata.num_age) ## 80datas * 70% = 56datas\n",
    "testdata.num_age = rawdata.num_age[ind==2,] \n",
    "str(testdata.num_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = CS ~ ., family = binomial, data = traindata.num_age)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.7656  -0.8930   0.2696   0.7518   1.9929  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)    0.95446    1.44035   0.663   0.5075  \n",
       "Age            0.03012    0.08426   0.357   0.7208  \n",
       "DN2            0.04250    0.80266   0.053   0.9578  \n",
       "DN3           -0.39535    1.33656  -0.296   0.7674  \n",
       "DN4           16.89548 2150.24360   0.008   0.9937  \n",
       "DT1           -1.12722    0.91685  -1.229   0.2189  \n",
       "DT2           -0.96034    0.93098  -1.032   0.3023  \n",
       "BP1           -1.99671    1.02044  -1.957   0.0504 .\n",
       "BP2            0.18724    1.04530   0.179   0.8578  \n",
       "HP1            1.73123    0.83863   2.064   0.0390 *\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 75.837  on 55  degrees of freedom\n",
       "Residual deviance: 54.993  on 46  degrees of freedom\n",
       "AIC: 74.993\n",
       "\n",
       "Number of Fisher Scoring iterations: 16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## logistic reg. for category data (numeric type about age only)\n",
    "full.fit_num_age = glm(CS~., family=binomial, data=traindata.num_age)\n",
    "summary(full.fit_num_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for profiling to be done...\n",
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>  -1.864947</td><td> 3.8934781 </td></tr>\n",
       "\t<tr><th scope=row>Age</th><td>  -0.138677</td><td> 0.1990255 </td></tr>\n",
       "\t<tr><th scope=row>DN2</th><td>  -1.536625</td><td> 1.6710164 </td></tr>\n",
       "\t<tr><th scope=row>DN3</th><td>  -3.011753</td><td> 2.4101886 </td></tr>\n",
       "\t<tr><th scope=row>DN4</th><td>-312.833520</td><td>        NA </td></tr>\n",
       "\t<tr><th scope=row>DT1</th><td>  -3.095064</td><td> 0.5863972 </td></tr>\n",
       "\t<tr><th scope=row>DT2</th><td>  -2.929587</td><td> 0.8162830 </td></tr>\n",
       "\t<tr><th scope=row>BP1</th><td>  -4.206230</td><td>-0.1195749 </td></tr>\n",
       "\t<tr><th scope=row>BP2</th><td>  -1.908930</td><td> 2.3035984 </td></tr>\n",
       "\t<tr><th scope=row>HP1</th><td>   0.173105</td><td> 3.5623229 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) &   -1.864947 &  3.8934781 \\\\\n",
       "\tAge &   -0.138677 &  0.1990255 \\\\\n",
       "\tDN2 &   -1.536625 &  1.6710164 \\\\\n",
       "\tDN3 &   -3.011753 &  2.4101886 \\\\\n",
       "\tDN4 & -312.833520 &         NA \\\\\n",
       "\tDT1 &   -3.095064 &  0.5863972 \\\\\n",
       "\tDT2 &   -2.929587 &  0.8162830 \\\\\n",
       "\tBP1 &   -4.206230 & -0.1195749 \\\\\n",
       "\tBP2 &   -1.908930 &  2.3035984 \\\\\n",
       "\tHP1 &    0.173105 &  3.5623229 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| (Intercept) |   -1.864947 |  3.8934781  | \n",
       "| Age |   -0.138677 |  0.1990255  | \n",
       "| DN2 |   -1.536625 |  1.6710164  | \n",
       "| DN3 |   -3.011753 |  2.4101886  | \n",
       "| DN4 | -312.833520 |         NA  | \n",
       "| DT1 |   -3.095064 |  0.5863972  | \n",
       "| DT2 |   -2.929587 |  0.8162830  | \n",
       "| BP1 |   -4.206230 | -0.1195749  | \n",
       "| BP2 |   -1.908930 |  2.3035984  | \n",
       "| HP1 |    0.173105 |  3.5623229  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %       97.5 %    \n",
       "(Intercept)   -1.864947  3.8934781\n",
       "Age           -0.138677  0.1990255\n",
       "DN2           -1.536625  1.6710164\n",
       "DN3           -3.011753  2.4101886\n",
       "DN4         -312.833520         NA\n",
       "DT1           -3.095064  0.5863972\n",
       "DT2           -2.929587  0.8162830\n",
       "BP1           -4.206230 -0.1195749\n",
       "BP2           -1.908930  2.3035984\n",
       "HP1            0.173105  3.5623229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>2.59727932142367</dd>\n",
       "\t<dt>Age</dt>\n",
       "\t\t<dd>1.03057801610931</dd>\n",
       "\t<dt>DN2</dt>\n",
       "\t\t<dd>1.04341982905049</dd>\n",
       "\t<dt>DN3</dt>\n",
       "\t\t<dd>0.67344505167936</dd>\n",
       "\t<dt>DN4</dt>\n",
       "\t\t<dd>21757735.95799</dd>\n",
       "\t<dt>DT1</dt>\n",
       "\t\t<dd>0.323932875959093</dd>\n",
       "\t<dt>DT2</dt>\n",
       "\t\t<dd>0.382762339351219</dd>\n",
       "\t<dt>BP1</dt>\n",
       "\t\t<dd>0.135781042414399</dd>\n",
       "\t<dt>BP2</dt>\n",
       "\t\t<dd>1.20591971587793</dd>\n",
       "\t<dt>HP1</dt>\n",
       "\t\t<dd>5.64759518640079</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 2.59727932142367\n",
       "\\item[Age] 1.03057801610931\n",
       "\\item[DN2] 1.04341982905049\n",
       "\\item[DN3] 0.67344505167936\n",
       "\\item[DN4] 21757735.95799\n",
       "\\item[DT1] 0.323932875959093\n",
       "\\item[DT2] 0.382762339351219\n",
       "\\item[BP1] 0.135781042414399\n",
       "\\item[BP2] 1.20591971587793\n",
       "\\item[HP1] 5.64759518640079\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   2.59727932142367Age\n",
       ":   1.03057801610931DN2\n",
       ":   1.04341982905049DN3\n",
       ":   0.67344505167936DN4\n",
       ":   21757735.95799DT1\n",
       ":   0.323932875959093DT2\n",
       ":   0.382762339351219BP1\n",
       ":   0.135781042414399BP2\n",
       ":   1.20591971587793HP1\n",
       ":   5.64759518640079\n",
       "\n"
      ],
      "text/plain": [
       " (Intercept)          Age          DN2          DN3          DN4          DT1 \n",
       "2.597279e+00 1.030578e+00 1.043420e+00 6.734451e-01 2.175774e+07 3.239329e-01 \n",
       "         DT2          BP1          BP2          HP1 \n",
       "3.827623e-01 1.357810e-01 1.205920e+00 5.647595e+00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confidence interval\n",
    "confint(full.fit_num_age)\n",
    "#odd's ratio\n",
    "exp(coef(full.fit_num_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>GVIF</th><th scope=col>Df</th><th scope=col>GVIF^(1/(2*Df))</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Age</th><td>1.426585</td><td>1       </td><td>1.194397</td></tr>\n",
       "\t<tr><th scope=row>DN</th><td>1.997602</td><td>3       </td><td>1.122238</td></tr>\n",
       "\t<tr><th scope=row>DT</th><td>1.529604</td><td>2       </td><td>1.112102</td></tr>\n",
       "\t<tr><th scope=row>BP</th><td>1.671006</td><td>2       </td><td>1.136958</td></tr>\n",
       "\t<tr><th scope=row>HP</th><td>1.364476</td><td>1       </td><td>1.168108</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & GVIF & Df & GVIF\\textasciicircum{}(1/(2*Df))\\\\\n",
       "\\hline\n",
       "\tAge & 1.426585 & 1        & 1.194397\\\\\n",
       "\tDN & 1.997602 & 3        & 1.122238\\\\\n",
       "\tDT & 1.529604 & 2        & 1.112102\\\\\n",
       "\tBP & 1.671006 & 2        & 1.136958\\\\\n",
       "\tHP & 1.364476 & 1        & 1.168108\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | GVIF | Df | GVIF^(1/(2*Df)) | \n",
       "|---|---|---|---|---|\n",
       "| Age | 1.426585 | 1        | 1.194397 | \n",
       "| DN | 1.997602 | 3        | 1.122238 | \n",
       "| DT | 1.529604 | 2        | 1.112102 | \n",
       "| BP | 1.671006 | 2        | 1.136958 | \n",
       "| HP | 1.364476 | 1        | 1.168108 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    GVIF     Df GVIF^(1/(2*Df))\n",
       "Age 1.426585 1  1.194397       \n",
       "DN  1.997602 3  1.122238       \n",
       "DT  1.529604 2  1.112102       \n",
       "BP  1.671006 2  1.136958       \n",
       "HP  1.364476 1  1.168108       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variance inflation factor\n",
    "vif(full.fit_num_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.789585040057462</li>\n",
       "\t<li>0.138743641903629</li>\n",
       "\t<li>0.532066871028549</li>\n",
       "\t<li>0.338849488609767</li>\n",
       "\t<li>0.345629645687968</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.789585040057462\n",
       "\\item 0.138743641903629\n",
       "\\item 0.532066871028549\n",
       "\\item 0.338849488609767\n",
       "\\item 0.345629645687968\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.789585040057462\n",
       "2. 0.138743641903629\n",
       "3. 0.532066871028549\n",
       "4. 0.338849488609767\n",
       "5. 0.345629645687968\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.7895850 0.1387436 0.5320669 0.3388495 0.3456296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & 1\\\\\n",
       "\\hline\n",
       "\t0 & 0\\\\\n",
       "\t1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 1 | \n",
       "|---|---|\n",
       "| 0 | 0 | \n",
       "| 1 | 1 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  1\n",
       "0 0\n",
       "1 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction in the range 0~1 (rseponse)\n",
    "traindata.num_age$prob = predict(full.fit_num_age, type=\"response\")\n",
    "traindata.num_age$prob[1:5]\n",
    "contrasts(traindata$CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 15  6\n",
       "  1  8 27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "traindata.num_age$predict = rep(0, length(traindata.num_age$prob)) # make empty vector as 0 (False)\n",
    "traindata.num_age$predict[traindata.num_age$prob>0.5] = 1 #fill vector if true (prob>0.5)\n",
    "confm=table(traindata.num_age$predict, traindata$CS)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.75"
      ],
      "text/latex": [
       "0.75"
      ],
      "text/markdown": [
       "0.75"
      ],
      "text/plain": [
       "[1] 0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy : (TN+TP)/(TN+FP+FN+TP)\n",
    "mean(traindata.num_age$predict == traindata.num_age$CS )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'table' int [1:2, 1:2] 15 8 6 27\n",
      " - attr(*, \"dimnames\")=List of 2\n",
      "  ..$ : chr [1:2] \"0\" \"1\"\n",
      "  ..$ : chr [1:2] \"0\" \"1\"\n",
      "'data.frame':\t4 obs. of  3 variables:\n",
      " $ Var1: Factor w/ 2 levels \"0\",\"1\": 1 2 1 2\n",
      " $ Var2: Factor w/ 2 levels \"0\",\"1\": 1 1 2 2\n",
      " $ Freq: int  15 8 6 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Var1</th><th scope=col>Var2</th><th scope=col>Freq</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0 </td><td>0 </td><td>15</td></tr>\n",
       "\t<tr><td>1 </td><td>0 </td><td> 8</td></tr>\n",
       "\t<tr><td>0 </td><td>1 </td><td> 6</td></tr>\n",
       "\t<tr><td>1 </td><td>1 </td><td>27</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Var1 & Var2 & Freq\\\\\n",
       "\\hline\n",
       "\t 0  & 0  & 15\\\\\n",
       "\t 1  & 0  &  8\\\\\n",
       "\t 0  & 1  &  6\\\\\n",
       "\t 1  & 1  & 27\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Var1 | Var2 | Freq | \n",
       "|---|---|---|---|\n",
       "| 0  | 0  | 15 | \n",
       "| 1  | 0  |  8 | \n",
       "| 0  | 1  |  6 | \n",
       "| 1  | 1  | 27 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Var1 Var2 Freq\n",
       "1 0    0    15  \n",
       "2 1    0     8  \n",
       "3 0    1     6  \n",
       "4 1    1    27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric(0)\n",
      "numeric(0)\n",
      "numeric(0)\n"
     ]
    }
   ],
   "source": [
    "str(confm)\n",
    "TN=as.integer(confm[1,1])\n",
    "FP=confm[0,1]\n",
    "TP=confm[2,2]\n",
    "FN=confm[1,0]\n",
    "conf = as.data.frame(confm)\n",
    "str(conf)\n",
    "conf\n",
    "#Precision\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(FN+TP)\n",
    "Accuracy = (TN+TP)/(TN+FP+FN+TP)\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  56 \n",
      "\n",
      " \n",
      "                          | traindata$CS \n",
      "traindata.num_age$predict |         0 |         1 | Row Total | \n",
      "--------------------------|-----------|-----------|-----------|\n",
      "                        0 |        15 |         6 |        21 | \n",
      "                          |     4.712 |     3.284 |           | \n",
      "                          |     0.714 |     0.286 |     0.375 | \n",
      "                          |     0.652 |     0.182 |           | \n",
      "                          |     0.268 |     0.107 |           | \n",
      "--------------------------|-----------|-----------|-----------|\n",
      "                        1 |         8 |        27 |        35 | \n",
      "                          |     2.827 |     1.970 |           | \n",
      "                          |     0.229 |     0.771 |     0.625 | \n",
      "                          |     0.348 |     0.818 |           | \n",
      "                          |     0.143 |     0.482 |           | \n",
      "--------------------------|-----------|-----------|-----------|\n",
      "             Column Total |        23 |        33 |        56 | \n",
      "                          |     0.411 |     0.589 |           | \n",
      "--------------------------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "List of 4\n",
      " $ t       : 'table' int [1:2, 1:2] 15 8 6 27\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ x: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ y: chr [1:2] \"0\" \"1\"\n",
      " $ prop.row: 'table' num [1:2, 1:2] 0.714 0.229 0.286 0.771\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ x: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ y: chr [1:2] \"0\" \"1\"\n",
      " $ prop.col: 'table' num [1:2, 1:2] 0.652 0.348 0.182 0.818\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ x: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ y: chr [1:2] \"0\" \"1\"\n",
      " $ prop.tbl: 'table' num [1:2, 1:2] 0.268 0.143 0.107 0.482\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ x: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ y: chr [1:2] \"0\" \"1\"\n",
      "[1] 0.8181818\n",
      "[1] 0.7714286\n",
      "[1] 0.75\n"
     ]
    }
   ],
   "source": [
    "library(gmodels)\n",
    "confm=CrossTable(traindata.num_age$predict, traindata$CS)\n",
    "#table(confm)\n",
    "str(confm)\n",
    "Precision=confm$prop.col[2,2]\n",
    "Recall=confm$prop.row[2,2]\n",
    "Accuracy = (confm$t[2,2]+confm$t[1,1])/sum(confm$t)\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 15  6\n",
       "         1  8 27\n",
       "                                          \n",
       "               Accuracy : 0.75            \n",
       "                 95% CI : (0.6163, 0.8561)\n",
       "    No Information Rate : 0.5893          \n",
       "    P-Value [Acc > NIR] : 0.009055        \n",
       "                                          \n",
       "                  Kappa : 0.4766          \n",
       " Mcnemar's Test P-Value : 0.789268        \n",
       "                                          \n",
       "            Sensitivity : 0.8182          \n",
       "            Specificity : 0.6522          \n",
       "         Pos Pred Value : 0.7714          \n",
       "         Neg Pred Value : 0.7143          \n",
       "             Prevalence : 0.5893          \n",
       "         Detection Rate : 0.4821          \n",
       "   Detection Prevalence : 0.6250          \n",
       "      Balanced Accuracy : 0.7352          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 15 8 6 27\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.75 0.477 0.616 0.856 0.589 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.818 0.652 0.771 0.714 0.771 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.8181818 \n",
      "Pos Pred Value \n",
      "     0.7714286 \n",
      "Accuracy \n",
      "    0.75 \n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(traindata.num_age$predict), as.factor(traindata$CS), positive=\"1\")\n",
    "# Sensitivity = Precision\n",
    "# Pos Pred Value = Recall\n",
    "# Accuracy\n",
    "confm\n",
    "str(confm)\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "    0 1\n",
       "  0 5 4\n",
       "  1 6 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.583333333333333"
      ],
      "text/latex": [
       "0.583333333333333"
      ],
      "text/markdown": [
       "0.583333333333333"
      ],
      "text/plain": [
       "[1] 0.5833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testdata.num_age$prob = predict(full.fit_num_age, newdata=testdata.num_age, type=\"response\")\n",
    "testdata.num_age$predict = rep(0, length(testdata.num_age$prob))\n",
    "testdata.num_age$predict[testdata.num_age$prob>0.5] = 1\n",
    "table(testdata.num_age$predict, testdata.num_age$CS)\n",
    "mean(testdata.num_age$predict == testdata.num_age$CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 5 4\n",
       "         1 6 9\n",
       "                                          \n",
       "               Accuracy : 0.5833          \n",
       "                 95% CI : (0.3664, 0.7789)\n",
       "    No Information Rate : 0.5417          \n",
       "    P-Value [Acc > NIR] : 0.4213          \n",
       "                                          \n",
       "                  Kappa : 0.1489          \n",
       " Mcnemar's Test P-Value : 0.7518          \n",
       "                                          \n",
       "            Sensitivity : 0.6923          \n",
       "            Specificity : 0.4545          \n",
       "         Pos Pred Value : 0.6000          \n",
       "         Neg Pred Value : 0.5556          \n",
       "             Prevalence : 0.5417          \n",
       "         Detection Rate : 0.3750          \n",
       "   Detection Prevalence : 0.6250          \n",
       "      Balanced Accuracy : 0.5734          \n",
       "                                          \n",
       "       'Positive' Class : 1               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ positive: chr \"1\"\n",
      " $ table   : 'table' int [1:2, 1:2] 5 6 4 9\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ Prediction: chr [1:2] \"0\" \"1\"\n",
      "  .. ..$ Reference : chr [1:2] \"0\" \"1\"\n",
      " $ overall : Named num [1:7] 0.583 0.149 0.366 0.779 0.542 ...\n",
      "  ..- attr(*, \"names\")= chr [1:7] \"Accuracy\" \"Kappa\" \"AccuracyLower\" \"AccuracyUpper\" ...\n",
      " $ byClass : Named num [1:11] 0.692 0.455 0.6 0.556 0.6 ...\n",
      "  ..- attr(*, \"names\")= chr [1:11] \"Sensitivity\" \"Specificity\" \"Pos Pred Value\" \"Neg Pred Value\" ...\n",
      " $ mode    : chr \"sens_spec\"\n",
      " $ dots    : list()\n",
      " - attr(*, \"class\")= chr \"confusionMatrix\"\n",
      "Sensitivity \n",
      "  0.6923077 \n",
      "Pos Pred Value \n",
      "           0.6 \n",
      " Accuracy \n",
      "0.5833333 \n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "confm=confusionMatrix(as.factor(testdata.num_age$predict), as.factor(testdata$CS), positive=\"1\")\n",
    "# Sensitivity = Precision\n",
    "# Pos Pred Value = Recall\n",
    "# Accuracy\n",
    "confm\n",
    "str(confm)\n",
    "Precision=confm$byClass[\"Sensitivity\"]\n",
    "Recall=confm$byClass[\"Pos Pred Value\"]\n",
    "Accuracy = confm$overall[\"Accuracy\"]\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: leaps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Age'</li>\n",
       "\t<li>'DN'</li>\n",
       "\t<li>'DT'</li>\n",
       "\t<li>'BP'</li>\n",
       "\t<li>'HP'</li>\n",
       "\t<li>'y'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Age'\n",
       "\\item 'DN'\n",
       "\\item 'DT'\n",
       "\\item 'BP'\n",
       "\\item 'HP'\n",
       "\\item 'y'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Age'\n",
       "2. 'DN'\n",
       "3. 'DT'\n",
       "4. 'BP'\n",
       "5. 'HP'\n",
       "6. 'y'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Age\" \"DN\"  \"DT\"  \"BP\"  \"HP\"  \"y\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Age</th><th scope=col>DN</th><th scope=col>DT</th><th scope=col>BP</th><th scope=col>HP</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 6</td><td>1 </td><td>0 </td><td>2 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10</td><td>2 </td><td>1 </td><td>1 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10</td><td>1 </td><td>1 </td><td>0 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>11</td><td>2 </td><td>0 </td><td>1 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>12</td><td>2 </td><td>0 </td><td>1 </td><td>0 </td><td>0 </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>11</td><td>1 </td><td>1 </td><td>1 </td><td>0 </td><td>1 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & Age & DN & DT & BP & HP & y\\\\\n",
       "\\hline\n",
       "\t1 &  6 & 1  & 0  & 2  & 0  & 0 \\\\\n",
       "\t3 & 10 & 2  & 1  & 1  & 0  & 0 \\\\\n",
       "\t6 & 10 & 1  & 1  & 0  & 0  & 0 \\\\\n",
       "\t7 & 11 & 2  & 0  & 1  & 0  & 0 \\\\\n",
       "\t9 & 12 & 2  & 0  & 1  & 0  & 0 \\\\\n",
       "\t10 & 11 & 1  & 1  & 1  & 0  & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Age | DN | DT | BP | HP | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 1 |  6 | 1  | 0  | 2  | 0  | 0  | \n",
       "| 3 | 10 | 2  | 1  | 1  | 0  | 0  | \n",
       "| 6 | 10 | 1  | 1  | 0  | 0  | 0  | \n",
       "| 7 | 11 | 2  | 0  | 1  | 0  | 0  | \n",
       "| 9 | 12 | 2  | 0  | 1  | 0  | 0  | \n",
       "| 10 | 11 | 1  | 1  | 1  | 0  | 1  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Age DN DT BP HP y\n",
       "1   6  1  0  2  0  0\n",
       "3  10  2  1  1  0  0\n",
       "6  10  1  1  0  0  0\n",
       "7  11  2  0  1  0  0\n",
       "9  12  2  0  1  0  0\n",
       "10 11  1  1  1  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t56 obs. of  6 variables:\n",
      " $ Age: num  6 10 10 11 12 11 17 7 4 13 ...\n",
      " $ DN : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 1 2 2 1 1 1 1 1 ...\n",
      " $ DT : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 2 2 1 1 2 2 2 1 3 ...\n",
      " $ BP : Factor w/ 3 levels \"0\",\"1\",\"2\": 3 2 1 2 2 2 1 2 2 1 ...\n",
      " $ HP : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ y  : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "#best subset reg.\n",
    "library(bestglm)\n",
    "cvdata = traindata.num_age[,-7:-8]\n",
    "orgcolname=colnames(rawdata)\n",
    "orgcolname[6]=\"y\"\n",
    "orgcolname\n",
    "colnames(cvdata)=orgcolname\n",
    "head(cvdata)\n",
    "#cvdata$y= as.numeric(traindata$CS)\n",
    "str(cvdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in bestglm(Xy = cvdata, IC = \"CV\", CVArgs = list(Method = \"HTF\", : Cross-validation not available when there are categorical variables with more than 2 levels!\n",
     "output_type": "error",
     "traceback": [
      "Error in bestglm(Xy = cvdata, IC = \"CV\", CVArgs = list(Method = \"HTF\", : Cross-validation not available when there are categorical variables with more than 2 levels!\nTraceback:\n",
      "1. bestglm(Xy = cvdata, IC = \"CV\", CVArgs = list(Method = \"HTF\", \n .     K + 10, REP = 1), family = binomial)",
      "2. stop(\"Cross-validation not available when there are categorical variables with more than 2 levels!\")"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"CV\", CVArgs=list(Method=\"HTF\", K+10, REP=1), family=binomial)\n",
    "summary(cvdata.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIC\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"BIC\", family=binomial)\n",
    "cvdata.bestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#attribute 'Age' { 22,26,28,27,32,36,33,23,20,29,25,37,24,18,30,40,31,19,21,35,17,38 }\n",
    "#attribute 'Delivery number' { 1,2,3,4 }\n",
    "#attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}\n",
    "#attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }\n",
    "#attribute 'Heart Problem' { 1,0 } -> {0 = apt, 1 = inept }\n",
    "#attribute Caesarian { 0,1 } -> {0 = No, 1 = Yes }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkcat=function(x,val) {\n",
    "    y=c()\n",
    "    y.length=length(x)\n",
    "    count=1\n",
    "    for(i in x){\n",
    "        #print(i)\n",
    "        #print(count)\n",
    "        if( i == val) { y[count] = 1}\n",
    "        else{ y[count] = 0}\n",
    "        count=count+1\n",
    "    }\n",
    "    return (y)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy data for pre-processing \n",
    "rawdata2=rawdata\n",
    "\n",
    "#change type for numeric data column=Age,DN(Delivery Number)\n",
    "rawdata2$Age=as.numeric(rawdata$Age)\n",
    "rawdata2$DN=as.numeric(rawdata$DN)\n",
    "\n",
    "#add cols for cateogry data\n",
    "# DT(delivery time) ->  DT0(timly=0), DT1(premature=1), 2(latecomer)\n",
    "rawdata2$DT0=mkcat(rawdata$DT, 0)\n",
    "rawdata2$DT1=mkcat(rawdata$DT, 1)\n",
    "rawdata2$DT2=mkcat(rawdata$DT, 2)\n",
    "\n",
    "#BP(Blood pressure) -> BP0(low=0), BP1(normal=1), 2(high)\n",
    "rawdata2$BP0=mkcat(rawdata$BP, 0)\n",
    "rawdata2$BP1=mkcat(rawdata$BP, 1)\n",
    "rawdata2$BP2=mkcat(rawdata$BP, 2)\n",
    "\n",
    "#HP(Heart Problem) -> HP0(apt=0), HP1(inept=1)\n",
    "rawdata2$HP0=mkcat(rawdata$HP, 0)\n",
    "rawdata2$HP1=mkcat(rawdata$HP, 1)\n",
    "\n",
    "#remove old data column\n",
    "str(rawdata2)\n",
    "rawdata3=rawdata2[-3:-5]\n",
    "str(rawdata3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make samples from data\n",
    "## dividing orginal data by ratio for tran, test\n",
    "\n",
    "#fix random seed\n",
    "set.seed(123)\n",
    "\n",
    "# make index vector(row number) for two type(x=2 : train, test) of samples \n",
    "# with probability weight : train:test = 7:3  \n",
    "# in number of sample=nrow(rawdata3)=80 )\n",
    "# replace : If TRUE, same data from orginal can be repeat in new sample\n",
    "ind = sample(2, nrow(rawdata3), replace=TRUE, prob=c(0.7,0.3))\n",
    "\n",
    "traindata.raw3 = rawdata3[ind==1,] \n",
    "str(traindata.raw3) ## 80datas * 70% = 56datas\n",
    "testdata.raw3 = rawdata3[ind==2,] \n",
    "str(testdata.raw3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the conservation of original data\n",
    "## check number of case CS=0 or 1\n",
    "table(rawdata3$CS)\n",
    "table(traindata$CS)\n",
    "table(testdata$CS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change data from wide type to long type \n",
    "library(reshape2)\n",
    "rawdata.m2 = melt(rawdata3[,-1], id.var=\"CS\")\n",
    "head(rawdata.m2)\n",
    "table(rawdata.m2$variable)\n",
    "## boxplot\n",
    "library(ggplot2)\n",
    "ggplot(data=rawdata.m2, aes(x=CS, y=value)) + geom_boxplot() + facet_wrap(~ variable, ncol=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best subset reg.\n",
    "library(bestglm)\n",
    "cvdata = traindata.raw3\n",
    "orgcolname=colnames(rawdata3)\n",
    "orgcolname[3]=\"y\"\n",
    "orgcolname\n",
    "colnames(cvdata)=orgcolname\n",
    "head(cvdata)\n",
    "cvdata$y= as.factor(traindata.raw3$DT0)\n",
    "#cvdata$y= as.numeric(traindata.raw3$CS)\n",
    "str(cvdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross validation for best subset log reg\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"CV\", CVArgs=list(Method=\"HTF\", K=3, REP=1), family=binomial)\n",
    "summary(cvdata.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIC\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"BIC\", family=binomial)\n",
    "cvdata.bestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROCs\n",
    "cvdata.bestset=bestglm(Xy=cvdata, IC=\"ROCs\", family=binomial)\n",
    "cvdata.bestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
